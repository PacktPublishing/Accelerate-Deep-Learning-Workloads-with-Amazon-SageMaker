{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto scaling\n",
    "\n",
    "In this example we will apply simple tracking policy to TF HuggingFace endppoint and load it with some synthethic traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download artifacts for DistilBert model for Question-Answering task\n",
    "\n",
    "! mkdir distilbert-base-uncased-distilled-squad\n",
    "! mkdir distilbert-base-uncased-distilled-squad/1\n",
    "! mkdir distilbert-base-uncased-distilled-squad/code\n",
    "\n",
    "! wget https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/saved_model.tar.gz\n",
    "! tar -zxvf saved_model.tar.gz -C distilbert-base-uncased-distilled-squad/1\n",
    "\n",
    "! cp 1_src/inference.py distilbert-base-uncased-distilled-squad/code\n",
    "! cp 1_src/requirements.txt distilbert-base-uncased-distilled-squad/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C \"$PWD\" -czf distilbert-base-uncased-distilled-squad.tar.gz distilbert-base-uncased-distilled-squad/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload model data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import os \n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "#role = get_execution_role()  # TODO: replace it\n",
    "role=\"arn:aws:iam::941656036254:role/service-role/AmazonSageMaker-ExecutionRole-20210904T193230\" # TODO: this has to be replaced\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'auto-scaling'\n",
    "s3_path = 's3://{}/{}'.format(bucket, prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-941656036254/auto-scaling/model-artifacts/distilbert-base-uncased-distilled-squad.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_data = sagemaker_session.upload_data('distilbert-base-uncased-distilled-squad.tar.gz',\n",
    "                                           bucket,\n",
    "                                           os.path.join(prefix, 'model-artifacts'))     \n",
    "print(model_data)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "env = { \"NLP_TASK\":\"question-answering\"\n",
    "    }\n",
    "\n",
    "# The \"Model\" object doesn't create a SageMaker Model until a Transform Job or Endpoint is created.\n",
    "tensorflow_serving_model = TensorFlowModel(model_data=model_data,\n",
    "                                 name=\"qa-tensorflow\",\n",
    "                                 role=role,\n",
    "                                 framework_version='2.8',\n",
    "                                 env=env,\n",
    "                                 sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Using already existing model: qa-tensorflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "instance = \"ml.c5.2xlarge\"\n",
    "\n",
    "predictor = tensorflow_serving_model.deploy(initial_instance_count=1, instance_type=instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sm_client = sagemaker_session.sagemaker_client\n",
    "runtime_sm_client = sagemaker_session.sagemaker_runtime_client\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointName': 'qa-tensorflow-2022-08-16-10-52-28-769',\n",
       " 'EndpointArn': 'arn:aws:sagemaker:us-east-1:941656036254:endpoint/qa-tensorflow-2022-08-16-10-52-28-769',\n",
       " 'EndpointConfigName': 'qa-tensorflow-2022-08-16-10-52-28-769',\n",
       " 'ProductionVariants': [{'VariantName': 'AllTraffic',\n",
       "   'DeployedImages': [{'SpecifiedImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.8-cpu',\n",
       "     'ResolvedImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference@sha256:d72f9623bab06fcf97cef4cad7a5748926f002a62503fc06c89fb29f09a2beaf',\n",
       "     'ResolutionTime': datetime.datetime(2022, 8, 16, 6, 52, 31, 135000, tzinfo=tzlocal())}],\n",
       "   'CurrentWeight': 1.0,\n",
       "   'DesiredWeight': 1.0,\n",
       "   'CurrentInstanceCount': 1,\n",
       "   'DesiredInstanceCount': 1}],\n",
       " 'EndpointStatus': 'InService',\n",
       " 'CreationTime': datetime.datetime(2022, 8, 16, 6, 52, 29, 188000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 8, 16, 6, 54, 23, 872000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '3571ef6a-59b5-4b1a-ba8e-27c009aac128',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '3571ef6a-59b5-4b1a-ba8e-27c009aac128',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '764',\n",
       "   'date': 'Tue, 16 Aug 2022 10:55:32 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.describe_endpoint(EndpointName=predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Multi Container Endpoint\n",
    "\n",
    "This has to be replaced with locust of some sort: https://github.com/arunprsh/SageMaker-Load-Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "article = r\"\"\"\n",
    "The Amazon rainforest (Portuguese: Floresta Amazônica or Amazônia; Spanish: Selva Amazónica, Amazonía or usually Amazonia; French: Forêt amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \"Amazonas\" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.\n",
    "\"\"\"\n",
    "\n",
    "question=\"What kind of forest is Amazon?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-cased-distilled-squad were not used when initializing TFDistilBertForQuestionAnswering: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased-distilled-squad and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#  preparing data for TF Serving format\n",
    "\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForQuestionAnswering\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "max_length = 384\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "model = TFDistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "encoded_input = tokenizer(question, article, padding='max_length', max_length=max_length)\n",
    "encoded_input = dict(encoded_input)\n",
    "qa_inputs = [{\"input_ids\": np.array(encoded_input[\"input_ids\"]).tolist(), \"attention_mask\":np.array(encoded_input[\"attention_mask\"]).tolist()}]\n",
    "#qa_inputs = {\"input_ids\": np.array(encoded_input[\"input_ids\"]).tolist(), \"attention_mask\":np.array(encoded_input[\"attention_mask\"]).tolist()}\n",
    "qa_inputs = {\"instances\" : qa_inputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tf_response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=\"application/json\",\n",
    "    Body=json.dumps(qa_inputs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = json.loads(tf_response[\"Body\"].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What kind of forest is Amazon?, answer: moist broadleaf forest\n"
     ]
    }
   ],
   "source": [
    "answer_start_index = int(tf.math.argmax(predictions['predictions'][0]['output_0']))\n",
    "answer_end_index = int(tf.math.argmax(predictions['predictions'][0]['output_1']))\n",
    "\n",
    "predict_answer_tokens = encoded_input[\"input_ids\"][answer_start_index : answer_end_index + 1]\n",
    "tf_response = tokenizer.decode(predict_answer_tokens)\n",
    "\n",
    "print(f\"Question: {question}, answer: {tf_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_file = \"3_src/payload.json\"\n",
    "json.dump(qa_inputs, open(payload_file, \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Scaling Policies\n",
    "\n",
    "We start from simple tracking policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "\n",
    "as_client = boto3.client('application-autoscaling') # Common class representing Application Auto Scaling for SageMaker amongst other services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_id='endpoint/' + predictor.endpoint_name + '/variant/' + 'AllTraffic' # This is the format in which application autoscaling references the endpoint\n",
    "\n",
    "response = as_client.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker', #\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=10\n",
    ")\n",
    "\n",
    "#Example 1 - SageMakerVariantInvocationsPerInstance Metric\n",
    "response = as_client.put_scaling_policy(\n",
    "    PolicyName='Invocations-ScalingPolicy',\n",
    "    ServiceNamespace='sagemaker', # The namespace of the AWS service that provides the resource. \n",
    "    ResourceId=resource_id, # Endpoint name \n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount', # SageMaker supports only Instance Count\n",
    "    PolicyType='TargetTrackingScaling', # 'StepScaling'|'TargetTrackingScaling'\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 10, # The target value for the metric. - here the metric is - SageMakerVariantInvocationsPerInstance\n",
    "        'PredefinedMetricSpecification': {\n",
    "            'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance', # is the average number of times per minute that each instance for a variant is invoked. \n",
    "        },\n",
    "        'ScaleInCooldown': 30, # The cooldown period helps you prevent your Auto Scaling group from launching or terminating \n",
    "                                # additional instances before the effects of previous activities are visible. \n",
    "                                # You can configure the length of time based on your instance startup time or other application needs.\n",
    "                                # ScaleInCooldown - The amount of time, in seconds, after a scale in activity completes before another scale in activity can start. \n",
    "        'ScaleOutCooldown': 30 # ScaleOutCooldown - The amount of time, in seconds, after a scale out activity completes before another scale out activity can start.\n",
    "        \n",
    "        # 'DisableScaleIn': True|False - ndicates whether scale in by the target tracking policy is disabled. \n",
    "                            # If the value is true , scale in is disabled and the target tracking policy won't remove capacity from the scalable resource.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoScaling client\n",
    "asg = boto3.client('application-autoscaling')\n",
    "\n",
    "# Resource type is variant and the unique identifier is the resource ID.\n",
    "resource_id=f\"endpoint/{predictor.endpoint_name}/variant/AllTraffic\"\n",
    "\n",
    "# scaling configuration\n",
    "response = asg.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker', #\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount', \n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=4\n",
    ")\n",
    "\n",
    "\n",
    "#Target Scaling\n",
    "response = asg.put_scaling_policy(\n",
    "    PolicyName=f'Request-ScalingPolicy-{predictor.endpoint_name}',\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    PolicyType='TargetTrackingScaling',\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 10.0, # Threshold\n",
    "        'PredefinedMetricSpecification': {\n",
    "            'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance',\n",
    "        },\n",
    "        'ScaleInCooldown': 300, # duration until scale in\n",
    "        'ScaleOutCooldown': 60 # duration between scale out\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PolicyARN': 'arn:aws:autoscaling:us-east-1:941656036254:scalingPolicy:9911d696-5a3c-448b-9d05-330a60aec097:resource/sagemaker/endpoint/qa-tensorflow-2022-08-16-10-52-28-769/variant/AllTraffic:policyName/Invocations-ScalingPolicy',\n",
       " 'Alarms': [{'AlarmName': 'TargetTracking-endpoint/qa-tensorflow-2022-08-16-10-52-28-769/variant/AllTraffic-AlarmHigh-c871eb1f-a787-421b-bb63-5713f6554e4d',\n",
       "   'AlarmARN': 'arn:aws:cloudwatch:us-east-1:941656036254:alarm:TargetTracking-endpoint/qa-tensorflow-2022-08-16-10-52-28-769/variant/AllTraffic-AlarmHigh-c871eb1f-a787-421b-bb63-5713f6554e4d'},\n",
       "  {'AlarmName': 'TargetTracking-endpoint/qa-tensorflow-2022-08-16-10-52-28-769/variant/AllTraffic-AlarmLow-76adac27-c8cf-48e3-ba0c-53f0a0751772',\n",
       "   'AlarmARN': 'arn:aws:cloudwatch:us-east-1:941656036254:alarm:TargetTracking-endpoint/qa-tensorflow-2022-08-16-10-52-28-769/variant/AllTraffic-AlarmLow-76adac27-c8cf-48e3-ba0c-53f0a0751772'}],\n",
       " 'ResponseMetadata': {'RequestId': '8d3f7498-e7dd-4837-b9fc-63a737b892f5',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '8d3f7498-e7dd-4837-b9fc-63a737b892f5',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '906',\n",
       "   'date': 'Tue, 16 Aug 2022 12:35:28 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running load tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r \"../utils/load_testing/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../utils/load_testing/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../utils/load_testing/config.py\n",
    "\n",
    "# provide configuration parameters\n",
    "# TODO: clean up config from personal data\n",
    "\n",
    "HOST = 'runtime.sagemaker.us-east-1.amazonaws.com'\n",
    "REGION = 'us-east-1'\n",
    "# replace the url below with the sagemaker endpoint you are load testing\n",
    "ENDPOINT_NAME = \"qa-tensorflow-2022-08-16-12-55-04-479\"\n",
    "SAGEMAKER_ENDPOINT_URL = f'https://runtime.sagemaker.us-east-1.amazonaws.com/endpoints/{ENDPOINT_NAME}/invocations'\n",
    "ACCESS_KEY = '<USE YOUR AWS ACCESS KEY HERE>'\n",
    "SECRET_KEY = '<USE YOUR AWS SECRET KEY HERE>'\n",
    "# replace the context type below as per your requirements\n",
    "CONTENT_TYPE = 'application/json'\n",
    "METHOD = 'POST'\n",
    "SERVICE = 'sagemaker'\n",
    "SIGNED_HEADERS = 'content-type;host;x-amz-date'\n",
    "CANONICAL_QUERY_STRING = ''\n",
    "ALGORITHM = 'AWS4-HMAC-SHA256'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start locust\n",
    "\n",
    "Beloew run in console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-08-17 12:50:03,998] C02Y82MBJGH5/INFO/locust.main: Run time limit set to 60 seconds\n",
      "[2022-08-17 12:50:03,998] C02Y82MBJGH5/INFO/locust.main: Starting Locust 2.11.0\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated       0     0(0.00%) |      0       0       0      0 |    0.00        0.00\n",
      "\n",
      "[2022-08-17 12:50:03,999] C02Y82MBJGH5/INFO/locust.runners: Ramping to 2 users at a rate of 1.00 per second\n",
      "[2022-08-17 12:50:05,000] C02Y82MBJGH5/INFO/locust.runners: All users spawned: {\"WebsiteUser\": 2} (2 total users)\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request      79  79(100.00%) |     37      25     238     30 |    0.00        0.00\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated      79  79(100.00%) |     37      25     238     30 |    0.00        0.00\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request     212 212(100.00%) |     32      25     238     30 |   26.33       26.33\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated     212 212(100.00%) |     32      25     238     30 |   26.33       26.33\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request     340 340(100.00%) |     31      25     238     30 |   42.20       42.20\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated     340 340(100.00%) |     31      25     238     30 |   42.20       42.20\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request     469 469(100.00%) |     31      25     238     30 |   48.43       48.43\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated     469 469(100.00%) |     31      25     238     30 |   48.43       48.43\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request     596 596(100.00%) |     31      25     238     30 |   50.50       50.50\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated     596 596(100.00%) |     31      25     238     30 |   50.50       50.50\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request     731 731(100.00%) |     31      23     238     30 |   59.60       59.60\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated     731 731(100.00%) |     31      23     238     30 |   59.60       59.60\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request     864 864(100.00%) |     30      23     238     30 |   65.00       65.00\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated     864 864(100.00%) |     30      23     238     30 |   65.00       65.00\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request     964 964(100.00%) |     31      23    1032     30 |   65.10       65.10\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated     964 964(100.00%) |     31      23    1032     30 |   65.10       65.10\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    1093 1093(100.00%) |     31      23    1032     30 |   65.30       65.30\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    1093 1093(100.00%) |     31      23    1032     30 |   65.30       65.30\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    1226 1226(100.00%) |     31      23    1032     30 |   62.50       62.50\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    1226 1226(100.00%) |     31      23    1032     30 |   62.50       62.50\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    1358 1358(100.00%) |     31      23    1032     30 |   62.90       62.90\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    1358 1358(100.00%) |     31      23    1032     30 |   62.90       62.90\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    1489 1489(100.00%) |     31      23    1032     30 |   62.70       62.70\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    1489 1489(100.00%) |     31      23    1032     30 |   62.70       62.70\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    1619 1619(100.00%) |     31      23    1032     30 |   62.70       62.70\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    1619 1619(100.00%) |     31      23    1032     30 |   62.70       62.70\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    1749 1749(100.00%) |     31      23    1032     30 |   65.60       65.60\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    1749 1749(100.00%) |     31      23    1032     30 |   65.60       65.60\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    1877 1877(100.00%) |     31      23    1032     30 |   65.80       65.80\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    1877 1877(100.00%) |     31      23    1032     30 |   65.80       65.80\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    1973 1973(100.00%) |     31      23    1032     30 |   65.20       65.20\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    1973 1973(100.00%) |     31      23    1032     30 |   65.20       65.20\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    2066 2066(100.00%) |     32      23    1032     30 |   62.90       62.90\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    2066 2066(100.00%) |     32      23    1032     30 |   62.90       62.90\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    2158 2158(100.00%) |     32      23    1032     30 |   59.10       59.10\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    2158 2158(100.00%) |     32      23    1032     30 |   59.10       59.10\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    2243 2243(100.00%) |     32      23    1032     30 |   55.60       55.60\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    2243 2243(100.00%) |     32      23    1032     30 |   55.60       55.60\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    2315 2315(100.00%) |     33      23    1032     30 |   49.60       49.60\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    2315 2315(100.00%) |     33      23    1032     30 |   49.60       49.60\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    2425 2425(100.00%) |     33      23    1032     30 |   43.50       43.50\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    2425 2425(100.00%) |     33      23    1032     30 |   43.50       43.50\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    2554 2554(100.00%) |     33      23    1032     30 |   45.20       45.20\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    2554 2554(100.00%) |     33      23    1032     30 |   45.20       45.20\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    2685 2685(100.00%) |     33      23    1032     30 |   48.60       48.60\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    2685 2685(100.00%) |     33      23    1032     30 |   48.60       48.60\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    2814 2814(100.00%) |     33      23    1032     30 |   52.30       52.30\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    2814 2814(100.00%) |     33      23    1032     30 |   52.30       52.30\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    2938 2938(100.00%) |     33      23    1032     30 |   56.70       56.70\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    2938 2938(100.00%) |     33      23    1032     30 |   56.70       56.70\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    3035 3035(100.00%) |     33      23    1032     30 |   62.30       62.30\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    3035 3035(100.00%) |     33      23    1032     30 |   62.30       62.30\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    3116 3116(100.00%) |     33      23    1032     30 |   60.80       60.80\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    3116 3116(100.00%) |     33      23    1032     30 |   60.80       60.80\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    3228 3228(100.00%) |     34      23    1032     30 |   56.20       56.20\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    3228 3228(100.00%) |     34      23    1032     30 |   56.20       56.20\n",
      "\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    3349 3349(100.00%) |     33      23    1032     30 |   54.40       54.40\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    3349 3349(100.00%) |     33      23    1032     30 |   54.40       54.40\n",
      "\n",
      "[2022-08-17 12:51:03,569] C02Y82MBJGH5/INFO/locust.main: --run-time limit reached. Stopping Locust\n",
      "[2022-08-17 12:51:03,574] C02Y82MBJGH5/INFO/locust.main: Shutting down (exit code 1)\n",
      "Type     Name  # reqs      # fails |    Avg     Min     Max    Med |   req/s  failures/s\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "POST     Post Request    3434 3434(100.00%) |     34      23    1032     30 |   57.66       57.66\n",
      "--------||-------|-------------|-------|-------|-------|-------|--------|-----------\n",
      "         Aggregated    3434 3434(100.00%) |     34      23    1032     30 |   57.66       57.66\n",
      "\n",
      "Response time percentiles (approximated)\n",
      "Type     Name      50%    66%    75%    80%    90%    95%    98%    99%  99.9% 99.99%   100% # reqs\n",
      "--------||--------|------|------|------|------|------|------|------|------|------|------|------\n",
      "POST     Post Request       30     31     32     33     36     44    110    130    350   1000   1000   3434\n",
      "--------||--------|------|------|------|------|------|------|------|------|------|------|------\n",
      "         Aggregated       30     31     32     33     36     44    110    130    350   1000   1000   3434\n",
      "\n",
      "Error report\n",
      "# occurrences      Error                                                                                               \n",
      "------------------|-------------------------------------------------------------\n",
      "3434               POST Post Request: HTTPError('400 Client Error: Bad Request for url: Post Request')                 \n",
      "------------------|-------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! locust -f ../utils/load_testing/locustfile.py --headless -u 2 -r 1 --run-time 1m\n",
    "# u - number of concurrent users\n",
    "# r - spawn rate (users per sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Updating\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: InService\n",
      "Current Instance count: 1\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "response = sm_client.describe_endpoint(EndpointName=predictor.endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Updating':\n",
    "    time.sleep(1)\n",
    "    response = sm_client.describe_endpoint(EndpointName=predictor.endpoint_name)\n",
    "    status = response['EndpointStatus']\n",
    "    instance_count = response['ProductionVariants'][0]['CurrentInstanceCount']\n",
    "    print(f\"Status: {status}\")\n",
    "    print(f\"Current Instance count: {instance_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02fb69b38420c3d4e00e3a2af627e83f052bc85ba6fe46654fe57240b48dcaee"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sagemaker2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
