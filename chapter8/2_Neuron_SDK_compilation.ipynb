{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 model for Inferentia\n",
    "Introduction:\n",
    "In this tutorial we will compile and deploy a ResNet50 model for inference on Inferentia.\n",
    "\n",
    "This Jupyter notebook should run on an inf1.6xlarge instance. The inference part of this tutorial requires an inf1 instance, not the compilation stage. For simplicity we will run this tutorial on an inf1.6xlarge, but in real life scenarios the compilation should be done on a compute instance and the deployment on an inf1 instance to save costs.\n",
    "\n",
    "In this tutorial we provide three main sections:\n",
    "\n",
    "Compile the ResNet50 model and infer with a batch size of 1\n",
    "\n",
    "Run the same compiled model on multiple NeuronCores using torch.neuron.DataParallel and dynamic batching\n",
    "\n",
    "Compile the ResNet50 model with a batch size of 5 and run it on multiple NeuronCores using torch.neuron.DataParallel for optimal performance on Inferentia\n",
    "\n",
    "Verify that this Jupyter notebook is running the Python kernel environment that was set up according to the PyTorch Installation Guide. You can select the kernel from the \"Kernel -> Change Kernel\" option on the top of this Jupyter notebook page.\n",
    "\n",
    "Install Dependencies:\n",
    "This tutorial requires the following pip packages:\n",
    "\n",
    "torch>=1.8\n",
    "torch-neuron\n",
    "torchvision\n",
    "neuron-cc[tensorflow]\n",
    "These will be installed by default when configuring your environment using the Neuron PyTorch setup guide.\n",
    "\n",
    "Compile model for Neuron\n",
    "The following step will compile the ResNet50 model for Inferentia. This will take a few minutes. At the end of script execution, the compiled model is saved as resnet50_neuron.pt in your local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms, datasets\n",
    "import torch_neuron\n",
    "\n",
    "# Create an example input for compilation\n",
    "image = torch.zeros([1, 3, 224, 224], dtype=torch.float32)\n",
    "\n",
    "# Load a pretrained ResNet50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "image = torch.zeros([1, 3, 224, 224], dtype=torch.float32)\n",
    "\n",
    "# Tell the model we are using it for evaluation (not training)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:The following operations are currently supported in torch-neuron for this model:\n",
      "INFO:Neuron:aten::batch_norm\n",
      "INFO:Neuron:aten::max_pool2d\n",
      "INFO:Neuron:aten::add\n",
      "INFO:Neuron:aten::_convolution\n",
      "INFO:Neuron:aten::adaptive_avg_pool2d\n",
      "INFO:Neuron:aten::flatten\n",
      "INFO:Neuron:aten::linear\n",
      "INFO:Neuron:prim::Constant\n",
      "INFO:Neuron:prim::ListConstruct\n",
      "INFO:Neuron:aten::relu\n",
      "INFO:Neuron:100.00% of all operations (including primitives) (1695 of 1695) are supported\n",
      "INFO:Neuron:100.00% of arithmetic operations (175 of 175) are supported\n",
      "INFO:Neuron:All operators are compiled by neuron-cc (this does not guarantee that neuron-cc will successfully compile)\n",
      "INFO:Neuron:Number of arithmetic operators (pre-compilation) before = 175, fused = 175, percent fused = 100.0%\n",
      "INFO:Neuron:Compiling function _NeuronGraph$1112 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ubuntu/pytorch_venv/bin/neuron-cc compile /tmp/tmpwhiu7gli/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /tmp/tmpwhiu7gli/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[1, 3, 224, 224], \"float32\"]}, \"outputs\": [\"Linear_22/aten_linear/Add:0\"]} --verbose 35'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:skip_inference_context for tensorboard symbols at /home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/tensorboard.py:305 tb_parse\n",
      "INFO:Neuron:Number of arithmetic operators (post-compilation) before = 175, compiled = 175, percent compiled = 100.0%\n",
      "INFO:Neuron:The neuron partitioner created 1 sub-graphs\n",
      "INFO:Neuron:Neuron successfully compiled 1 sub-graphs, Total fused subgraphs = 1, Percent of model sub-graphs successfully compiled = 100.0%\n",
      "INFO:Neuron:Compiled these operators (and operator counts) to Neuron:\n",
      "INFO:Neuron: => aten::_convolution: 53\n",
      "INFO:Neuron: => aten::adaptive_avg_pool2d: 1\n",
      "INFO:Neuron: => aten::add: 16\n",
      "INFO:Neuron: => aten::batch_norm: 53\n",
      "INFO:Neuron: => aten::flatten: 1\n",
      "INFO:Neuron: => aten::linear: 1\n",
      "INFO:Neuron: => aten::max_pool2d: 1\n",
      "INFO:Neuron: => aten::relu: 49\n",
      "INFO:Neuron:skip_inference_context for tensorboard symbols at /home/ubuntu/pytorch_venv/lib/python3.7/site-packages/torch_neuron/tensorboard.py:305 tb_parse\n",
      "INFO:Neuron:Number of neuron graph operations 1 did not match traced graph 4 - using heuristic matching of hierarchical information\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Analyze the model - this will show operator support and operator count\n",
    "torch.neuron.analyze_model(model, example_inputs=[image])\n",
    "\n",
    "# Compile the model using torch.neuron.trace to create a Neuron model\n",
    "# that that is optimized for the Inferentia hardware\n",
    "model_neuron = torch.neuron.trace(model, example_inputs=[image])\n",
    "\n",
    "# The output of the compilation step will report the percentage of operators that \n",
    "# are compiled to Neuron, for example:\n",
    "#\n",
    "# INFO:Neuron:The neuron partitioner created 1 sub-graphs\n",
    "# INFO:Neuron:Neuron successfully compiled 1 sub-graphs, Total fused subgraphs = 1, Percent of model sub-graphs successfully compiled = 100.0%\n",
    "# \n",
    "# We will also be warned if there are operators that are not placed on the Inferentia hardware\n",
    "\n",
    "# Save the compiled model\n",
    "model_neuron.save(\"resnet50_neuron.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on Inferentia\n",
    "We can use the compiled Neuron model to run inference on Inferenita.\n",
    "\n",
    "In the following example, we preprocess a sample image for inference using the CPU model and Neuron model. We compare the predicted labels from the CPU model and Neuron model to verify that they are the same.\n",
    "\n",
    "Important: Do not perform inference with a Neuron traced model on a non-Neuron supported instance, as the results will not be calculated properly.\n",
    "\n",
    "Define a preprocessing function\n",
    "We define a basic image preprocessing function that loads a sample image and labels, normalizes and batches the image, and transforms the image into a tensor for inference using the compiled Neuron model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Prepare inference samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from urllib import request\n",
    "\n",
    "os.makedirs(\"./torch_neuron_test/images\", exist_ok=True)\n",
    "request.urlretrieve(\"https://raw.githubusercontent.com/awslabs/mxnet-model-server/master/docs/images/kitten_small.jpg\",\n",
    "                    \"./torch_neuron_test/images/kitten_small.jpg\")\n",
    "\n",
    "request.urlretrieve(\"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\",\"imagenet_class_index.json\")\n",
    "idx2label = []\n",
    "\n",
    "with open(\"imagenet_class_index.json\", \"r\") as read_file:\n",
    "    class_idx = json.load(read_file)\n",
    "    idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess(batch_size=1, num_neuron_cores=1):\n",
    "    # Define a normalization function using the ImageNet mean and standard deviation\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # Resize the sample image to [1, 3, 224, 224], normalize it, and turn it into a tensor\n",
    "    eval_dataset = datasets.ImageFolder(\n",
    "        os.path.dirname(\"./torch_neuron_test/\"),\n",
    "        transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "        ])\n",
    "    )\n",
    "    image, _ = eval_dataset[0]\n",
    "    image = torch.tensor(image.numpy()[np.newaxis, ...])\n",
    "\n",
    "    # Create a \"batched\" image with enough images to go on each of the available NeuronCores\n",
    "    # batch_size is the per-core batch size\n",
    "    # num_neuron_cores is the number of NeuronCores being used\n",
    "    batch_image = image\n",
    "    for i in range(batch_size * num_neuron_cores - 1):\n",
    "        batch_image = torch.cat([batch_image, image], 0)\n",
    "     \n",
    "    return batch_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference using the Neuron model\n",
    "We import the necessary python modules, load the torch-neuron compiled model, and run inference on Inferentia.\n",
    "\n",
    "By default, the Neuron model will run on a single NeuronCore. In the next section, we will see how to run the Neuron model on multiple NeuronCores to fully saturate our hardware for optimal performance on Inferentia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-Jul-06 16:03:10.0776 29541:29541 ERROR   NRT:nrt_init                                Unable to determine Neuron Driver version. Please check aws-neuron-dkms package is installed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The PyTorch Neuron Runtime could not be initialized. Neuron Driver issues are logged\nto your system logs. See the Neuron Runtime's troubleshooting guide for help on this\ntopic: https://awsdocs-neuron.readthedocs-hosted.com/en/latest/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29541/1414164618.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load the compiled Neuron model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel_neuron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet50_neuron.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Run inference using the Neuron model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_venv/lib/python3.7/site-packages/torch_neuron/jit_load_wrapper.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mscript_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjit_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mfound_neuron_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscript_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_venv/lib/python3.7/site-packages/torch/jit/_serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, _extra_files)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mcu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompilationUnit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mcpp_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_ir_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_extra_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         cpp_module = torch._C.import_ir_module_from_buffer(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The PyTorch Neuron Runtime could not be initialized. Neuron Driver issues are logged\nto your system logs. See the Neuron Runtime's troubleshooting guide for help on this\ntopic: https://awsdocs-neuron.readthedocs-hosted.com/en/latest/"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms, datasets\n",
    "import torch_neuron\n",
    "\n",
    "# Get a sample image\n",
    "image = preprocess()\n",
    "\n",
    "# Run inference using the CPU model\n",
    "output_cpu = model(image)\n",
    "\n",
    "# Load the compiled Neuron model\n",
    "model_neuron = torch.jit.load('resnet50_neuron.pt')\n",
    "\n",
    "# Run inference using the Neuron model\n",
    "output_neuron = model_neuron(image)\n",
    "\n",
    "# Verify that the CPU and Neuron predictions are the same by comparing\n",
    "# the top-5 results\n",
    "top5_cpu = output_cpu[0].sort()[1][-5:]\n",
    "top5_neuron = output_neuron[0].sort()[1][-5:]\n",
    "\n",
    "# Lookup and print the top-5 labels\n",
    "top5_labels_cpu = [idx2label[idx] for idx in top5_cpu]\n",
    "top5_labels_neuron = [idx2label[idx] for idx in top5_neuron]\n",
    "print(\"CPU top-5 labels: {}\".format(top5_labels_cpu))\n",
    "print(\"Neuron top-5 labels: {}\".format(top5_labels_neuron))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Inference using torch.neuron.DataParallel\n",
    "To fully leverage the Inferentia hardware we want to use all avaialable NeuronCores. An inf1.xlarge and inf1.2xlarge have four NeuronCores, an inf1.6xlarge has 16 NeuronCores, and an inf1.24xlarge has 64 NeuronCores. For maximum performance on Inferentia hardware, we can use torch.neuron.DataParallel to utilize all available NeuronCores.\n",
    "\n",
    "torch.neuron.DataParallel implements data parallelism at the module level by duplicating the Neuron model on all available NeuronCores and distributing data across the different cores for parallelized inference.\n",
    "\n",
    "In the following section, we will run inference using the torch.neuron.DataParallel module to fully saturate the Inferentia hardware. We benchmark the model to collect throughput and latency statistics.\n",
    "\n",
    "Note: torch.neuron.DataParallel is new with Neuron 1.16.0. Please ensure you are using the latest Neuron package to run the following sections.\n",
    "\n",
    "Define a benchmarking function\n",
    "We create a function that handles benchmarking the Neuron model to collect throughput and latency metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def benchmark(model, image):\n",
    "    print('Input image shape is {}'.format(list(image.shape)))\n",
    "    \n",
    "    # The first inference loads the model so exclude it from timing \n",
    "    results = model(image)\n",
    "    \n",
    "    # Collect throughput and latency metrics\n",
    "    latency = []\n",
    "    throughput = []\n",
    "\n",
    "    # Run inference for 100 iterations and calculate metrics\n",
    "    num_infers = 100\n",
    "    for _ in range(num_infers):\n",
    "        delta_start = time()\n",
    "        results = model(image)\n",
    "        delta = time() - delta_start\n",
    "        latency.append(delta)\n",
    "        throughput.append(image.size(0)/delta)\n",
    "    \n",
    "    # Calculate and print the model throughput and latency\n",
    "    print(\"Avg. Throughput: {:.0f}, Max Throughput: {:.0f}\".format(np.mean(throughput), np.max(throughput)))\n",
    "    print(\"Latency P50: {:.0f}\".format(np.percentile(latency, 50)*1000.0))\n",
    "    print(\"Latency P90: {:.0f}\".format(np.percentile(latency, 90)*1000.0))\n",
    "    print(\"Latency P95: {:.0f}\".format(np.percentile(latency, 95)*1000.0))\n",
    "    print(\"Latency P99: {:.0f}\\n\".format(np.percentile(latency, 99)*1000.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Run Inference using torch.neuron.DataParallel\n",
    "We create the torch.neuron.DataParallel module using the compiled Neuron model, get a sample image, and benchmark the parallelized model on Neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a torch.neuron.DataParallel module using the compiled Neuron model\n",
    "# By default, torch.neuron.DataParallel will use four cores on an inf1.xlarge\n",
    "# or inf1.2xlarge, 16 cores on an inf1.6xlarge, and 24 cores on an inf1.24xlarge\n",
    "model_neuron_parallel = torch.neuron.DataParallel(model_neuron)\n",
    "\n",
    "# Get sample image with batch size=1 per NeuronCore\n",
    "batch_size = 1\n",
    "\n",
    "# For an inf1.xlarge or inf1.2xlarge, set num_neuron_cores = 4\n",
    "num_neuron_cores = 16\n",
    "\n",
    "image = preprocess(batch_size=batch_size, num_neuron_cores=num_neuron_cores)\n",
    "\n",
    "# Benchmark the model\n",
    "benchmark(model_neuron_parallel, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and Infer with different batch sizes on multiple NeuronCores\n",
    "Dynamic batching using small batch sizes can result in sub-optimal throughput because it involves slicing tensors into chunks and iteratively sending data to the hardware. Using a larger batch size at compilation time can use the Inferentia hardware more efficiently in order to maximize throughput. You can test the tradeoff between individual request latency and total throughput by fine-tuning the input batch size.\n",
    "\n",
    "In the following example, we recompile our model using a batch size of 5 and run the model using torch.neuron.DataParallel to fully saturate our Inferentia hardware for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input with batch size 5 for compilation\n",
    "batch_size = 5\n",
    "image = torch.zeros([batch_size, 3, 224, 224], dtype=torch.float32)\n",
    "\n",
    "# Recompile the ResNet50 model for inference with batch size 5\n",
    "model_neuron = torch.neuron.trace(model, example_inputs=[image])\n",
    "\n",
    "# Export to saved model\n",
    "model_neuron.save(\"resnet50_neuron_b{}.pt\".format(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "# Load compiled Neuron model\n",
    "model_neuron = torch.jit.load(\"resnet50_neuron_b{}.pt\".format(batch_size))\n",
    "\n",
    "# Create DataParallel model\n",
    "model_neuron_parallel = torch.neuron.DataParallel(model_neuron)\n",
    "\n",
    "# Get sample image with batch size=5\n",
    "image = preprocess(batch_size=batch_size, num_neuron_cores=num_neuron_cores)\n",
    "\n",
    "# Benchmark the model\n",
    "benchmark(model_neuron_parallel, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "https://github.com/aws/aws-neuron-sdk/blob/master/src/examples/pytorch/pipeline_tutorial/neuroncore_pipeline_pytorch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Cores in the Pipeline Mode\n",
    "neuroncore_pipeline_cores = 4 # This string should be '4' on an inf1.xlarge\n",
    "\n",
    "# Compiling for neuroncore-pipeline-cores='16'\n",
    "neuron_pipeline_model = torch.neuron.trace(model,\n",
    "                                           example_inputs=[image],\n",
    "                                           verbose=1,\n",
    "                                           compiler_args = ['--neuroncore-pipeline-cores', str(neuroncore_pipeline_cores)]\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = neuron_pipeline_model(*image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Neuron PyTorch)",
   "language": "python",
   "name": "pytorch_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
