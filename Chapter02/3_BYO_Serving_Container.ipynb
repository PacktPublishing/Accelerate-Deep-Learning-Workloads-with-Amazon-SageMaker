{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22e2bd5",
   "metadata": {},
   "source": [
    "## BYO Serving Container on SageMaker\n",
    "\n",
    "In this notebook, we will develop SageMaker-compatible container for inference. There are many scenarios when you may need to create a custom container, such as: \n",
    "- You have unique runtime requirements which cannot be addressed by extending prebuilt container. \n",
    "- You want to compile frameworks and libraries from sources for specific hardware platform.\n",
    "- You are using DL frameworks which are not supported natively by SageMaker (for instance, JAX). \n",
    "\n",
    "Building a custom container compatible with SageMaker inference and training resources requires development efforts, understanding of Docker containers, and specific SageMaker requirements. Therefore, itâ€™s usually recommended to consider script mode or extending a prebuilt container first and choosing to BYO container only if the first options do not work for your particular use case. \n",
    "\n",
    "We will use latest TensorFlow container as a base image and use AWS Multi-Model Server (\"MMS\") as a model server. Please note that MMS is one of several ML model serving options available for you.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "1. This sample assumes that you have AWS CLI v2 installed. Refer to this article for installatino details: https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html\n",
    "2. To push containers to private ECR, make sure that your SageMaker execution role has enough permissions for this operation. Refer to this article for details: https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-push.html\n",
    "\n",
    "## Problem Overview\n",
    "We will use pre-trained [VGG16 model](https://arxiv.org/pdf/1409.1556.pdf) to classify content of the images into 1000 categories. The model is trained on ImageNet dataset. We will use Keras Deep Learning library which is now a part of TensorFlow code base. Hence, we choose choose latest TensorFlow container as a base. \n",
    "\n",
    "## Developing Serving Container\n",
    "When deploying serving container to endpoint SageMaker runs `docker run <YOUR CONTAINER> serve` command. To comply with this requirement it's reccommended to use exec format of ENTRYPOINT instruction in your Dockerfile.\n",
    "\n",
    "Let's review our BYO Dockerfile:\n",
    "- we use latest tensorflow-devel container as base.\n",
    "- we install general and SageMaker specific dependencies.\n",
    "- we copy our model serving scripts to container.\n",
    "- we specify ENTRYPOINT and CMD instructions to comply with SageMaker requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ede50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize -O linenos=1 -l docker 3_sources/Dockerfile.inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb9df3",
   "metadata": {},
   "source": [
    "### Developing Model Serving Scripts\n",
    "\n",
    "Inference scripts in case of BYO container are specific to chosen model server. In our case we are using AWS MMS server and developed scripts according to it's requirements. You find more details here: https://github.com/awslabs/multi-model-server/blob/master/docs/custom_service.md\n",
    "\n",
    "In this example we don't intend to cover MMS and development of inference scripts in details. However, it's worth highlighting some key script aspects:\n",
    "- `dockerd_entrypoint.py` is an excuitable which starts MMS server when `serve` argument is passed to it.\n",
    "- `model_handler.py` implements model loading and model serving logics. Note, that method `handle()` checks if model is already loaded into memory. If it's not, it will load model into memory once and then proceed to handling serving request which includes:\n",
    "    - deserializing request payload.\n",
    "    - running predictions.\n",
    "    - serializing predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6284679",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize 3_sources/src/dockerd_entrypoint.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c5fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize 3_sources/src/model_handler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b87b66",
   "metadata": {},
   "source": [
    "### Building BYO Container\n",
    "\n",
    "Once we have Dockerfile and inference scripts are ready, we can proceed and build container. We start by importing SageMaker utilities and providing configuration settings for our container and SageMaker model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb320207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = session.boto_region_name\n",
    "\n",
    "# Configuration settings\n",
    "model_name=\"vgg16-model\"\n",
    "endpoint_name= model_name+\"-mms-endpoint\"\n",
    "image_uri = f\"{account}.dkr.ecr.{region}.amazonaws.com/{model_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9093606d",
   "metadata": {},
   "source": [
    "Now, we need to authenticate in our private ECR before we can push there BYO container image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05517ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to your private ECR\n",
    "!aws ecr get-login-password --region $region | docker login --username AWS --password-stdin {account}.dkr.ecr.{region}.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf6c1b",
   "metadata": {},
   "source": [
    "After that we are ready to build BYO container and push it to ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./build_and_push.sh {model_name} 3_sources/Dockerfile.inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea7a3a",
   "metadata": {},
   "source": [
    "## Deploying SageMaker Endpoint\n",
    "\n",
    "We use generic `Model` object to configure SageMaker model and endpoint which allows us to use BYO container image. Note, that since we download model from HuggingFace model hub in our training script, we don't need to provide `model_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d716e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import Model\n",
    "\n",
    "mms_model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=None,\n",
    "    role=role,\n",
    "    name=model_name,\n",
    "    sagemaker_session=session\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518180e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = mms_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\", \n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e6a62",
   "metadata": {},
   "source": [
    "## Test SageMaker Endpoint\n",
    "\n",
    "To test the endpoint we will use a sample image. Feel free to pick several other images of your choice (make sure they have object belonging to one of 1000 categories from ImageNet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f43a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE = \"sample_image.jpg\"\n",
    "! wget -O {TEST_IMAGE} https://farm1.static.flickr.com/56/152004091_5bfbc69bb3.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdc59aa",
   "metadata": {},
   "source": [
    "VGG16 model expects an image of size 224x224 pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc910437",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def resize_image(filename):\n",
    "    img = cv2.imread(TEST_IMAGE)\n",
    "    resized_img = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    resized_filename = \"resized_\"+TEST_IMAGE\n",
    "\n",
    "    cv2.imwrite(resized_filename, resized_img)\n",
    "\n",
    "    plt.imshow(cv2.imread(resized_filename))\n",
    "    plt.show()\n",
    "    \n",
    "    return resized_filename\n",
    "\n",
    "resized_test_image = resize_image(TEST_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ffdcba",
   "metadata": {},
   "source": [
    "To test the endpoint, we will use `boto3.sagemaker-runtime` client which allows to construct HTTP request and send it to defined SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c7651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "accept_type = \"application/json\"\n",
    "content_type = 'image/jpeg'\n",
    "headers = {'content-type': content_type}\n",
    "payload = open(resized_test_image, 'rb')\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=payload,\n",
    "    ContentType=content_type,\n",
    "    Accept = accept_type\n",
    ")\n",
    "\n",
    "\n",
    "most_likely_label = response['Body'].read()\n",
    "\n",
    "print(most_likely_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35c783",
   "metadata": {},
   "source": [
    "## Resource Cleanup\n",
    "\n",
    "Execute the cell below to delete cloud resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "mms_model.delete_model()\n",
    "\n",
    "# Delete container image\n",
    "ecr = boto3.client(\"ecr\")\n",
    "ecr.delete_repository(repositoryName=model_name, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6fd32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm {TEST_IMAGE}\n",
    "! rm {resized_test_image}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d149a4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, we developed a custom BYO serving container. As you may observe, developing BYO container is most flexible approach to configure runtime. However, it requires more development efforts and expertise than using pre-built SageMaker DL images."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02fb69b38420c3d4e00e3a2af627e83f052bc85ba6fe46654fe57240b48dcaee"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
