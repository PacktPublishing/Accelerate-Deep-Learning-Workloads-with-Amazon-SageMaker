{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket:\n",
      "sagemaker-us-east-1-941656036254\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = \"arn:aws:iam::941656036254:role/service-role/AmazonSageMaker-ExecutionRole-20210904T193230\"\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/sm-modelparallel-distribution-options'\n",
    "print('Bucket:\\n{}'.format(bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.84.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"s3://sagemaker-us-east-1-941656036254/hymenoptera_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugger configuration\n",
    "\n",
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile, Rule, ProfilerRule, rule_configs\n",
    "\n",
    "profiler_config=ProfilerConfig(\n",
    "    system_monitor_interval_millis=1000,\n",
    "    framework_profile_params=None\n",
    ")\n",
    "\n",
    "rules=[ \n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "mpioptions = \"-verbose -x orte_base_help_aggregate=0 \"\n",
    "instance_type = 'ml.p2.xlarge'\n",
    "instance_count = 2\n",
    "\n",
    "smd_mp_estimator = PyTorch(\n",
    "          entry_point=\"train_sm_mp.py\", # Pick your train script\n",
    "          source_dir='4_sources',\n",
    "          role=role,\n",
    "          instance_type=instance_type,\n",
    "          sagemaker_session=sagemaker_session,\n",
    "          framework_version='1.10',\n",
    "          py_version='py38',\n",
    "          instance_count=instance_count,\n",
    "          hyperparameters={\n",
    "              \"batch-size\":64,\n",
    "              \"epochs\":30,\n",
    "              \"model-name\":\"squeezenet\",\n",
    "              \"num-classes\": 2,\n",
    "              \"feature-extract\":True,\n",
    "            #  \"sync-s3-path\":f\"s3://{bucket}/distributed-training/output\"\n",
    "          },\n",
    "          disable_profiler=True,\n",
    "          debugger_hook_config=False,\n",
    "          distribution={\n",
    "              \"smdistributed\": {\n",
    "                  \"modelparallel\": {\n",
    "                      \"enabled\":True,\n",
    "                      \"parameters\": {\n",
    "                          \"microbatches\": 8, # The number of microbatches to perform pipelining over. 1 means no pipelining. Batch size must be divisible by the number of microbatches.\n",
    "                                             # A microbatch is a smaller subset of a given training mini-batch. The pipeline schedule determines which microbatch is executed by which device for every time slot.   \n",
    "                          \"placement_strategy\": \"cluster\", # more advanced topic: https://sagemaker.readthedocs.io/en/stable/api/training/smd_model_parallel_general.html#placement-strategy-with-tensor-parallelism \n",
    "                          \"pipeline\": \"interleaved\",\n",
    "                          \"optimize\": \"speed\", \n",
    "                        #  \"pipeline_parallel_degree\": 2, # The number of partitions to split the model into. this is only in newer libs\n",
    "                          \"partitions\": 2,\n",
    "                          \"auto_partition\": True,\n",
    "                          \"ddp\": False, # enables hybrid parallelism: model + data. Makes sense in multi-GPU nodes only.\n",
    "                      }\n",
    "                  }\n",
    "              },\n",
    "              \"mpi\": {\n",
    "                    \"enabled\": True, # must be enabled\n",
    "                    \"processes_per_host\": 1, # Pick your processes_per_host\n",
    "                    \"custom_mpi_options\": mpioptions \n",
    "              },\n",
    "          },\n",
    "          base_job_name=\"SMD-MP-demo\",\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-09 20:35:32 Starting - Starting the training job......\n",
      "2022-04-09 20:36:08 Starting - Preparing the instances for training.........\n",
      "2022-04-09 20:37:38 Downloading - Downloading input data...\n",
      "2022-04-09 20:38:14 Training - Downloading the training image..............................\n",
      "2022-04-09 20:43:37 Training - Training image download completed. Training in progress..bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2022-04-09 20:43:40,910 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2022-04-09 20:43:40,934 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2022-04-09 20:43:40,944 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2022-04-09 20:43:41,759 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "2022-04-09 20:43:41,759 sagemaker-training-toolkit INFO     Creating SSH daemon.\n",
      "2022-04-09 20:43:41,764 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\n",
      "2022-04-09 20:43:41,769 sagemaker-training-toolkit INFO     Cannot connect to host algo-2\n",
      "2022-04-09 20:43:41,769 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.145.15\n",
      "2022-04-09 20:43:42,770 sagemaker-training-toolkit INFO     Cannot connect to host algo-2\n",
      "2022-04-09 20:43:42,770 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.145.15\n",
      "2022-04-09 20:43:43,784 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\n",
      "2022-04-09 20:43:43,883 paramiko.transport INFO     Authentication (publickey) successful!\n",
      "2022-04-09 20:43:43,883 sagemaker-training-toolkit INFO     Can connect to host algo-2\n",
      "2022-04-09 20:43:43,884 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\n",
      "2022-04-09 20:43:43,884 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1', 'algo-2'] Hosts: ['algo-1', 'algo-2'] process_per_hosts: 1 num_processes: 2\n",
      "2022-04-09 20:43:43,887 sagemaker-training-toolkit INFO     Network interface name: eth0\n",
      "2022-04-09 20:43:43,915 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": false,\n",
      "        \"sagemaker_instance_type\": \"ml.p2.xlarge\",\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"-verbose -x orte_base_help_aggregate=0 \",\n",
      "        \"sagemaker_mpi_enabled\": true,\n",
      "        \"sagemaker_mpi_num_of_processes_per_host\": 1\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"epochs\": 30,\n",
      "        \"feature-extract\": false,\n",
      "        \"model-name\": \"squeezenet\",\n",
      "        \"mp_parameters\": {\n",
      "            \"microbatches\": 8,\n",
      "            \"placement_strategy\": \"cluster\",\n",
      "            \"pipeline\": \"interleaved\",\n",
      "            \"optimize\": \"speed\",\n",
      "            \"partitions\": 2,\n",
      "            \"auto_partition\": true,\n",
      "            \"ddp\": false\n",
      "        },\n",
      "        \"num-classes\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"SMD-MP-demo-2022-04-09-20-35-32-067\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-941656036254/SMD-MP-demo-2022-04-09-20-35-32-067/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_sm_mp\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p2.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p2.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-2\",\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_sm_mp.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch-size\":64,\"epochs\":30,\"feature-extract\":false,\"model-name\":\"squeezenet\",\"mp_parameters\":{\"auto_partition\":true,\"ddp\":false,\"microbatches\":8,\"optimize\":\"speed\",\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num-classes\":2}\n",
      "SM_USER_ENTRY_POINT=train_sm_mp.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p2.xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose -x orte_base_help_aggregate=0 \",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":1}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"train\",\"val\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_MODULE_NAME=train_sm_mp\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=1\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-941656036254/SMD-MP-demo-2022-04-09-20-35-32-067/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p2.xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose -x orte_base_help_aggregate=0 \",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":1},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":30,\"feature-extract\":false,\"model-name\":\"squeezenet\",\"mp_parameters\":{\"auto_partition\":true,\"ddp\":false,\"microbatches\":8,\"optimize\":\"speed\",\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"},\"num-classes\":2},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"SMD-MP-demo-2022-04-09-20-35-32-067\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-941656036254/SMD-MP-demo-2022-04-09-20-35-32-067/source/sourcedir.tar.gz\",\"module_name\":\"train_sm_mp\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_sm_mp.py\"}\n",
      "SM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"30\",\"--feature-extract\",\"False\",\"--model-name\",\"squeezenet\",\"--mp_parameters\",\"auto_partition=True,ddp=False,microbatches=8,optimize=speed,partitions=2,pipeline=interleaved,placement_strategy=cluster\",\"--num-classes\",\"2\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_CHANNEL_VAL=/opt/ml/input/data/val\n",
      "SM_HP_BATCH-SIZE=64\n",
      "SM_HP_EPOCHS=30\n",
      "SM_HP_FEATURE-EXTRACT=false\n",
      "SM_HP_MODEL-NAME=squeezenet\n",
      "SM_HP_MP_PARAMETERS={\"auto_partition\":true,\"ddp\":false,\"microbatches\":8,\"optimize\":\"speed\",\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"cluster\"}\n",
      "SM_HP_NUM-CLASSES=2\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/urllib3-1.26.8-py3.8.egg\n",
      "Invoking script with the following command:\n",
      "mpirun --host algo-1,algo-2 -np 2 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so -verbose -x orte_base_help_aggregate=0 -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_TRAIN -x SM_CHANNEL_VAL -x SM_HP_BATCH-SIZE -x SM_HP_EPOCHS -x SM_HP_FEATURE-EXTRACT -x SM_HP_MODEL-NAME -x SM_HP_MP_PARAMETERS -x SM_HP_NUM-CLASSES -x PYTHONPATH /opt/conda/bin/python3.8 -m mpi4py train_sm_mp.py --batch-size 64 --epochs 30 --feature-extract False --model-name squeezenet --mp_parameters auto_partition=True,ddp=False,microbatches=8,optimize=speed,partitions=2,pipeline=interleaved,placement_strategy=cluster --num-classes 2\n",
      "[algo-1:00042] Warning: could not find environment variable \"SM_HP_BATCH-SIZE\"\n",
      "[algo-1:00042] Warning: could not find environment variable \"SM_HP_FEATURE-EXTRACT\"\n",
      "[algo-1:00042] Warning: could not find environment variable \"SM_HP_MODEL-NAME\"\n",
      "[algo-1:00042] Warning: could not find environment variable \"SM_HP_NUM-CLASSES\"\n",
      "Warning: Permanently added 'algo-2,10.0.145.15' (ECDSA) to the list of known hosts.\n",
      "Data for JOB [41164,1] offset 0 Total slots allocated 2\n",
      " ========================   JOB MAP   ========================\n",
      " Data for node: algo-1#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [41164,1] App: 0 Process rank: 0 Bound: N/A\n",
      " Data for node: algo-2#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [41164,1] App: 0 Process rank: 1 Bound: N/A\n",
      " =============================================================\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2022-04-09 20:43:40,822 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2022-04-09 20:43:40,852 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2022-04-09 20:43:40,863 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2022-04-09 20:43:41,587 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "2022-04-09 20:43:41,587 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\n",
      "2022-04-09 20:43:41,590 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\n",
      "2022-04-09 20:43:41,590 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.161.248\n",
      "2022-04-09 20:43:42,606 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\n",
      "2022-04-09 20:43:42,792 paramiko.transport INFO     Authentication (publickey) successful!\n",
      "2022-04-09 20:43:42,793 sagemaker-training-toolkit INFO     Can connect to host algo-1\n",
      "2022-04-09 20:43:42,793 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\n",
      "2022-04-09 20:43:42,793 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\n",
      "2022-04-09 20:43:42,800 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\n",
      "2022-04-09 20:43:44,805 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=51, name='orted', status='sleeping', started='20:43:44')]\n",
      "2022-04-09 20:43:44,805 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=51, name='orted', status='sleeping', started='20:43:44')]\n",
      "2022-04-09 20:43:44,805 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=51, name='orted', status='sleeping', started='20:43:44')]\n",
      "[1,mpirank:1,algo-2]<stderr>:/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "[1,mpirank:1,algo-2]<stderr>:  warn(f\"Failed to load image Python extension: {e}\")\n",
      "[1,mpirank:1,algo-2]<stdout>:Collected args: Namespace(batch_size=64, epochs=30, feature_extract=True, model_name='squeezenet', mp_parameters='auto_partition=True,ddp=False,microbatches=8,optimize=speed,partitions=2,pipeline=interleaved,placement_strategy=cluster', num_classes=2, sync_s3_path='', use_pretrained=True). Following args are not parsed and won't be used: [].\n",
      "[1,mpirank:1,algo-2]<stdout>:Parsed SDT params are: Namespace(auto_partition=True, ddp=False, microbatches=8, optimize='speed', partitions=2, pipeline='interleaved', placement_strategy='cluster')\n",
      "[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "[1,mpirank:0,algo-1]<stderr>:  warn(f\"Failed to load image Python extension: {e}\")\n",
      "[1,mpirank:0,algo-1]<stdout>:Collected args: Namespace(batch_size=64, epochs=30, feature_extract=True, model_name='squeezenet', mp_parameters='auto_partition=True,ddp=False,microbatches=8,optimize=speed,partitions=2,pipeline=interleaved,placement_strategy=cluster', num_classes=2, sync_s3_path='', use_pretrained=True). Following args are not parsed and won't be used: [].\n",
      "[1,mpirank:0,algo-1]<stdout>:Parsed SDT params are: Namespace(auto_partition=True, ddp=False, microbatches=8, optimize='speed', partitions=2, pipeline='interleaved', placement_strategy='cluster')\n",
      "[1,mpirank:1,algo-2]<stderr>:Downloading: \"https://download.pytorch.org/models/squeezenet1_0-b66bff10.pth\" to /root/.cache/torch/hub/checkpoints/squeezenet1_0-b66bff10.pth\n",
      "[1,mpirank:1,algo-2]<stderr>:#015  0%|          | 0.00/4.78M [00:00<?, ?B/s]\n",
      "[1,mpirank:1,algo-2]<stderr>:#015 82%|████████▏ | 3.90M/4.78M [00:00<00:00, 40.9MB/s]\n",
      "[1,mpirank:1,algo-2]<stderr>:#015100%|██████████| 4.78M/4.78M [00:00<00:00, 43.8MB/s]\n",
      "[1,mpirank:1,algo-2]<stdout>:SqueezeNet(\n",
      "[1,mpirank:1,algo-2]<stdout>:  (features): Sequential(\n",
      "[1,mpirank:1,algo-2]<stdout>:    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "[1,mpirank:1,algo-2]<stdout>:    (1): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:    (3): Fire(\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:    )\n",
      "[1,mpirank:1,algo-2]<stdout>:    (4): Fire(\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:    )\n",
      "[1,mpirank:1,algo-2]<stdout>:    (5): Fire(\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:    )\n",
      "[1,mpirank:1,algo-2]<stdout>:    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:    (7): Fire(\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:    )\n",
      "[1,mpirank:1,algo-2]<stdout>:    (8): Fire(\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:    )\n",
      "[1,mpirank:1,algo-2]<stdout>:    (9): Fire(\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:    )\n",
      "[1,mpirank:1,algo-2]<stdout>:    (10): Fire(\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:    )\n",
      "[1,mpirank:1,algo-2]<stdout>:    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:    (12): Fire(\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:    )\n",
      "[1,mpirank:1,algo-2]<stdout>:  )\n",
      "[1,mpirank:1,algo-2]<stdout>:  (classifier): Sequential(\n",
      "[1,mpirank:1,algo-2]<stdout>:    (0): Dropout(p=0.5, inplace=False)\n",
      "[1,mpirank:1,algo-2]<stdout>:    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:    (2): ReLU(inplace=True)\n",
      "[1,mpirank:1,algo-2]<stdout>:    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "[1,mpirank:1,algo-2]<stdout>:  )\n",
      "[1,mpirank:1,algo-2]<stdout>:)\n",
      "[1,mpirank:0,algo-1]<stderr>:Downloading: \"https://download.pytorch.org/models/squeezenet1_0-b66bff10.pth\" to /root/.cache/torch/hub/checkpoints/squeezenet1_0-b66bff10.pth\n",
      "[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0.00/4.78M [00:00<?, ?B/s]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 4.78M/4.78M [00:00<00:00, 80.5MB/s]\n",
      "[1,mpirank:0,algo-1]<stdout>:SqueezeNet(\n",
      "[1,mpirank:0,algo-1]<stdout>:  (features): Sequential(\n",
      "[1,mpirank:0,algo-1]<stdout>:    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "[1,mpirank:0,algo-1]<stdout>:    (1): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:    (3): Fire(\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:    )\n",
      "[1,mpirank:0,algo-1]<stdout>:    (4): Fire(\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:    )\n",
      "[1,mpirank:0,algo-1]<stdout>:    (5): Fire(\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:    )\n",
      "[1,mpirank:0,algo-1]<stdout>:    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:    (7): Fire(\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:    )\n",
      "[1,mpirank:0,algo-1]<stdout>:    (8): Fire(\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:    )\n",
      "[1,mpirank:0,algo-1]<stdout>:    (9): Fire(\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:    )\n",
      "[1,mpirank:0,algo-1]<stdout>:    (10): Fire(\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:    )\n",
      "[1,mpirank:0,algo-1]<stdout>:    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:    (12): Fire(\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (squeeze_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand1x1_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:      (expand3x3_activation): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:    )\n",
      "[1,mpirank:0,algo-1]<stdout>:  )\n",
      "[1,mpirank:0,algo-1]<stdout>:  (classifier): Sequential(\n",
      "[1,mpirank:0,algo-1]<stdout>:    (0): Dropout(p=0.5, inplace=False)\n",
      "[1,mpirank:0,algo-1]<stdout>:    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:    (2): ReLU(inplace=True)\n",
      "[1,mpirank:0,algo-1]<stdout>:    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "[1,mpirank:0,algo-1]<stdout>:  )\n",
      "[1,mpirank:0,algo-1]<stdout>:)\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:51.791: I smdistributed/modelparallel/torch/throttler.py:37] Using NCCL throttle limit of 8.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.220: I smdistributed/modelparallel/backend/config.py:230] Configuration parameters:\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.220: I smdistributed/modelparallel/backend/config.py:233]   pipeline_parallel_degree: 2\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.220: I smdistributed/modelparallel/backend/config.py:233]   microbatches: 8\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.221: I smdistributed/modelparallel/backend/config.py:233]   pipeline: interleaved\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.221: I smdistributed/modelparallel/backend/config.py:233]   horovod: False\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.221: I smdistributed/modelparallel/backend/config.py:233]   ddp: False\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.221: I smdistributed/modelparallel/backend/config.py:233]   tensor_parallel_degree: 1\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.221: I smdistributed/modelparallel/backend/config.py:233]   ddp_port: None\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.221: I smdistributed/modelparallel/backend/config.py:233]   ddp_dist_backend: nccl\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.222: I smdistributed/modelparallel/backend/config.py:233]   contiguous: True\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.222: I smdistributed/modelparallel/backend/config.py:233]   placement_strategy: cluster\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.222: I smdistributed/modelparallel/backend/config.py:233]   optimize: speed\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.222: I smdistributed/modelparallel/backend/config.py:233]   default_partition: None\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.222: I smdistributed/modelparallel/backend/config.py:233]   auto_partition: True\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.222: I smdistributed/modelparallel/backend/config.py:233]   prescaled_batch: False\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.222: I smdistributed/modelparallel/backend/config.py:233]   memory_weight: 0.8\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.223: I smdistributed/modelparallel/backend/config.py:233]   active_microbatches: 4\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.223: I smdistributed/modelparallel/backend/config.py:233]   fp16_params: False\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.223: I smdistributed/modelparallel/backend/config.py:233]   tensor_parallel_seed: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.223: I smdistributed/modelparallel/backend/config.py:233]   offload_activations: False\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.223: I smdistributed/modelparallel/backend/config.py:233]   shard_optimizer_state: False\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.223: I smdistributed/modelparallel/backend/config.py:233]   skip_tracing: False\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:57.223: I smdistributed/modelparallel/backend/config.py:233]   activation_loading_horizon: 4\n",
      "[1,mpirank:0,algo-1]<stdout>:SMP DP size:1\n",
      "[1,mpirank:0,algo-1]<stdout>:SMP DP rank:0\n",
      "[1,mpirank:1,algo-2]<stdout>:SMP DP size:1\n",
      "[1,mpirank:1,algo-2]<stdout>:SMP DP rank:0\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:43:58.033: I smdistributed/modelparallel/torch/worker.py:296] Tracing on GPU. If the model parameters do not fit in a single GPU, you can set trace_device to `cpu`.\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.251: I smdistributed/modelparallel/torch/model.py:493] Partition assignments:\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.252: I smdistributed/modelparallel/torch/model.py:502] main: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.252: I smdistributed/modelparallel/torch/model.py:502] main/module: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.252: I smdistributed/modelparallel/torch/model.py:502] main/module/features: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.252: I smdistributed/modelparallel/torch/model.py:502] main/module/classifier: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.253: I smdistributed/modelparallel/torch/model.py:502] main/module/features/0: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.253: I smdistributed/modelparallel/torch/model.py:502] main/module/features/1: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.253: I smdistributed/modelparallel/torch/model.py:502] main/module/features/2: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.253: I smdistributed/modelparallel/torch/model.py:502] main/module/features/3: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.254: I smdistributed/modelparallel/torch/model.py:502] main/module/features/4: 0\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.254: I smdistributed/modelparallel/torch/model.py:502] main/module/features/5: 1\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.254: I smdistributed/modelparallel/torch/model.py:502] main/module/features/6: 1\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.254: I smdistributed/modelparallel/torch/model.py:502] main/module/features/7: 1\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.254: I smdistributed/modelparallel/torch/model.py:502] main/module/features/8: 1\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.255: I smdistributed/modelparallel/torch/model.py:502] main/module/features/9: 1\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.255: I smdistributed/modelparallel/torch/model.py:502] main/module/features/10: 1\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.255: I smdistributed/modelparallel/torch/model.py:502] main/module/features/11: 1\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.255: I smdistributed/modelparallel/torch/model.py:502] main/module/features/12: 1\n",
      "[1,mpirank:1,algo-2]<stdout>:[2022-04-09 20:44:02.263: I smdistributed/modelparallel/torch/model.py:427] Number of parameters on partition 1 are 36. 0 require grads\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.265: I smdistributed/modelparallel/torch/model.py:427] Number of parameters on partition 0 are 16. 2 require grads\n",
      "[1,mpirank:0,algo-1]<stdout>:[2022-04-09 20:44:02.270: I smdistributed/modelparallel/torch/model.py:548] Finished partitioning the model\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 0 [0/244 (0%)]#011Loss: 0.558909\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5811256770215003 at 0 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5811, Accuracy: 71/153 (46%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5811256770215003 at 0 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [0/244 (0%)]#011Loss: 0.672922\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5741497582080317 at 1 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5741, Accuracy: 81/153 (53%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5741497582080317 at 1 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [0/244 (0%)]#011Loss: 0.602862\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5685324855879241 at 2 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5685, Accuracy: 84/153 (55%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5685324855879241 at 2 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [0/244 (0%)]#011Loss: 0.558780\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5617904351427664 at 3 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5618, Accuracy: 85/153 (56%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5617904351427664 at 3 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [0/244 (0%)]#011Loss: 0.540527\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5555, Accuracy: 88/153 (58%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.555487642101213 at 4 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.555487642101213 at 4 epoch.[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [0/244 (0%)]#011Loss: 0.507634\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5500, Accuracy: 89/153 (58%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5499906352922028 at 5 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5499906352922028 at 5 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [0/244 (0%)]#011Loss: 0.493889\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5461534986308977 at 6 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5462, Accuracy: 90/153 (59%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5461534986308977 at 6 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [0/244 (0%)]#011Loss: 0.474352\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5432, Accuracy: 94/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5431669319377226 at 7 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5431669319377226 at 7 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [0/244 (0%)]#011Loss: 0.476340\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5408, Accuracy: 94/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5408241250156577 at 8 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5408241250156577 at 8 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [0/244 (0%)]#011Loss: 0.486567\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5391, Accuracy: 94/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5390678605223014 at 9 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5390678605223014 at 9 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [0/244 (0%)]#011Loss: 0.447453[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5377, Accuracy: 94/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5377124431086522 at 10 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5377124431086522 at 10 epoch.[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [0/244 (0%)]#011Loss: 0.447218\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5367, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5367008564518947 at 11 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5367008564518947 at 11 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [0/244 (0%)]#011Loss: 0.443007\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5360, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5359990456525017 at 12 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5359990456525017 at 12 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [0/244 (0%)]#011Loss: 0.437023\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5354, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5354305420046538 at 13 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5354305420046538 at 13 epoch.[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [0/244 (0%)]#011Loss: 0.427869\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5350025463727565 at 14 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5350, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5350025463727565 at 14 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 15 [0/244 (0%)]#011Loss: 0.435916\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5347, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.534713985094058 at 15 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.534713985094058 at 15 epoch.[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 16 [0/244 (0%)]#011Loss: 0.435418\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5345, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.534475518207924 at 16 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.534475518207924 at 16 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 17 [0/244 (0%)]#011Loss: 0.429915\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.534329768099816 at 17 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5343, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.534329768099816 at 17 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 18 [0/244 (0%)]#011Loss: 0.439364\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5342353418761608 at 18 epoch.[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5342, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5342353418761608 at 18 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 19 [0/244 (0%)]#011Loss: 0.416663\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5342, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5341527664583493 at 19 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5341527664583493 at 19 epoch.[1,mpirank:1,algo-2]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 20 [0/244 (0%)]#011Loss: 0.447248\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5341, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5341031255285724 at 20 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5341031255285724 at 20 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 21 [0/244 (0%)]#011Loss: 0.421698\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5341, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5340665212643692 at 21 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5340665212643692 at 21 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 22 [0/244 (0%)]#011Loss: 0.442532\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5340, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5340397544935638 at 22 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5340397544935638 at 22 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 23 [0/244 (0%)]#011Loss: 0.443422\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5340, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.534021443011714 at 23 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.534021443011714 at 23 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 24 [0/244 (0%)]#011Loss: 0.439728\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5340, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5340107157339458 at 24 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5340107157339458 at 24 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 25 [0/244 (0%)]#011Loss: 0.439465\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5340012584636414 at 25 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5340, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5340012584636414 at 25 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 26 [0/244 (0%)]#011Loss: 0.436180\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5339946248172934 at 26 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5340, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5339946248172934 at 26 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 27 [0/244 (0%)]#011Loss: 0.449654\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5339898019055136 at 27 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5340, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5339898019055136 at 27 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 28 [0/244 (0%)]#011Loss: 0.437235\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5339861555037155 at 28 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5340, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5339861555037155 at 28 epoch.\n",
      "[1,mpirank:0,algo-1]<stdout>:Train Epoch: 29 [0/244 (0%)]#011Loss: 0.448316\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.5340, Accuracy: 93/153 (61%)\n",
      "[1,mpirank:0,algo-1]<stdout>:\n",
      "[1,mpirank:0,algo-1]<stdout>:Test loss=0.5339838928646512 at 29 epoch.\n",
      "[1,mpirank:1,algo-2]<stdout>:Test loss=0.5339838928646512 at 29 epoch.\n",
      "[1,mpirank:0,algo-1]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\n",
      "[1,mpirank:1,algo-2]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set[1,mpirank:1,algo-2]<stderr>:\n",
      "2022-04-09 20:46:09,860 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "2022-04-09 20:46:09,859 sagemaker-training-toolkit INFO     Orted process exited\n",
      "\n",
      "2022-04-09 20:46:48 Uploading - Uploading generated training model2022-04-09 20:46:39,888 sagemaker-training-toolkit INFO     MPI process finished.\n",
      "2022-04-09 20:46:39,888 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2022-04-09 20:46:53 Completed - Training job completed\n",
      "Training seconds: 1110\n",
      "Billable seconds: 1110\n"
     ]
    }
   ],
   "source": [
    "smd_mp_estimator.fit(inputs={\"train\":f\"{data_url}/train\", \"val\":f\"{data_url}/val\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cae6ef5e525c6d5a8daa33565a4e32326fcdb22bb4405c41032726ef6ebbb77e"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
