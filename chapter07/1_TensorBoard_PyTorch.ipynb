{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket:\n",
      "sagemaker-us-east-1-941656036254\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = \"arn:aws:iam::941656036254:role/service-role/AmazonSageMaker-ExecutionRole-20210904T193230\"\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/sm-modelparallel-distribution-options'\n",
    "print('Bucket:\\n{}'.format(bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to stream TB data  from S3 location need to install \n",
    "!pip install tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.__version__   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"s3://sagemaker-us-east-1-941656036254/hymenoptera_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-1-941656036254'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Script\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize 1_sources/train_resnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "instance_type = 'ml.p2.xlarge'\n",
    "instance_count = 1\n",
    "job_name = \"pytorch-tb-profiling-2\"\n",
    "\n",
    "estimator = PyTorch(\n",
    "          entry_point=\"train_resnet_tb.py\", # Pick your train script\n",
    "          source_dir='1_sources',\n",
    "          role=role,\n",
    "          instance_type=instance_type,\n",
    "          sagemaker_session=sagemaker_session,\n",
    "          image_uri=\"763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.10.2-gpu-py38-cu113-ubuntu20.04-sagemaker\",\n",
    "          instance_count=instance_count,\n",
    "          hyperparameters={\n",
    "              \"batch-size\":16,\n",
    "              \"num-epochs\":5,\n",
    "              \"input-size\" : 224,\n",
    "              \"feature-extract\":False,\n",
    "              \"tb-s3-url\": f\"s3://{bucket}/tensorboard/{job_name}\",\n",
    "              \"num-data-workers\": 4\n",
    "          },\n",
    "          disable_profiler=True,\n",
    "          debugger_hook_config=False,\n",
    "          base_job_name=job_name,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-28 16:09:49 Starting - Starting the training job...\n",
      "2022-05-28 16:10:16 Starting - Preparing the instances for training.........\n",
      "2022-05-28 16:11:39 Downloading - Downloading input data...\n",
      "2022-05-28 16:12:20 Training - Downloading the training image.................................\n",
      "2022-05-28 16:17:47 Training - Training image download completed. Training in progress..bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2022-05-28 16:17:51,135 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2022-05-28 16:17:51,165 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2022-05-28 16:17:51,174 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2022-05-28 16:17:51,793 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.8 -m pip install -r requirements.txt\n",
      "Collecting setuptools==59.5.0\n",
      "Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 952.4/952.4 kB 36.1 MB/s eta 0:00:00\n",
      "Collecting torch-tb-profiler\n",
      "Downloading torch_tb_profiler-0.4.0-py3-none-any.whl (1.1 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 47.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from torch-tb-profiler->-r requirements.txt (line 2)) (1.4.2)\n",
      "Collecting tensorboard!=2.1.0,>=1.15\n",
      "Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 53.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.0.0->torch-tb-profiler->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.0.0->torch-tb-profiler->-r requirements.txt (line 2)) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.0.0->torch-tb-profiler->-r requirements.txt (line 2)) (1.22.2)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 69.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard!=2.1.0,>=1.15->torch-tb-profiler->-r requirements.txt (line 2)) (2.1.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 156.7/156.7 kB 12.1 MB/s eta 0:00:00\n",
      "Collecting absl-py>=0.4\n",
      "Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.7/126.7 kB 16.8 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.8/97.8 kB 15.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard!=2.1.0,>=1.15->torch-tb-profiler->-r requirements.txt (line 2)) (0.37.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 38.3 MB/s eta 0:00:00\n",
      "Collecting grpcio>=1.24.3\n",
      "Downloading grpcio-1.46.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 55.2 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorboard!=2.1.0,>=1.15->torch-tb-profiler->-r requirements.txt (line 2)) (3.20.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard!=2.1.0,>=1.15->torch-tb-profiler->-r requirements.txt (line 2)) (2.27.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard!=2.1.0,>=1.15->torch-tb-profiler->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch-tb-profiler->-r requirements.txt (line 2)) (4.7.2)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "Downloading cachetools-5.1.0-py3-none-any.whl (9.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 26.5 MB/s eta 0:00:00\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard!=2.1.0,>=1.15->torch-tb-profiler->-r requirements.txt (line 2)) (4.11.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard!=2.1.0,>=1.15->torch-tb-profiler->-r requirements.txt (line 2)) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard!=2.1.0,>=1.15->torch-tb-profiler->-r requirements.txt (line 2)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard!=2.1.0,>=1.15->torch-tb-profiler->-r requirements.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard!=2.1.0,>=1.15->torch-tb-profiler->-r requirements.txt (line 2)) (1.26.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard!=2.1.0,>=1.15->torch-tb-profiler->-r requirements.txt (line 2)) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.1.0,>=1.15->torch-tb-profiler->-r requirements.txt (line 2)) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.5/151.5 kB 16.1 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorboard-plugin-wit, tensorboard-data-server, setuptools, pyasn1-modules, oauthlib, grpcio, cachetools, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, torch-tb-profiler\n",
      "Attempting uninstall: setuptools\n",
      "Found existing installation: setuptools 62.3.2\n",
      "Uninstalling setuptools-62.3.2:\n",
      "Successfully uninstalled setuptools-62.3.2\n",
      "Successfully installed absl-py-1.0.0 cachetools-5.1.0 google-auth-2.6.6 google-auth-oauthlib-0.4.6 grpcio-1.46.3 markdown-3.3.7 oauthlib-3.2.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 setuptools-59.5.0 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torch-tb-profiler-0.4.0\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "2022-05-28 16:18:03,440 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 16,\n",
      "        \"feature-extract\": false,\n",
      "        \"input-size\": 224,\n",
      "        \"num-epochs\": 5,\n",
      "        \"tb-s3-url\": \"s3://sagemaker-us-east-1-941656036254/tensorboard/pytorch-tb-profiling-2\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-tb-profiling-2-2022-05-28-16-09-48-370\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-941656036254/pytorch-tb-profiling-2-2022-05-28-16-09-48-370/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_resnet_tb\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p2.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p2.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_resnet_tb.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch-size\":16,\"feature-extract\":false,\"input-size\":224,\"num-epochs\":5,\"tb-s3-url\":\"s3://sagemaker-us-east-1-941656036254/tensorboard/pytorch-tb-profiling-2\"}\n",
      "SM_USER_ENTRY_POINT=train_resnet_tb.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"train\",\"val\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_MODULE_NAME=train_resnet_tb\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=1\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-941656036254/pytorch-tb-profiling-2-2022-05-28-16-09-48-370/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":16,\"feature-extract\":false,\"input-size\":224,\"num-epochs\":5,\"tb-s3-url\":\"s3://sagemaker-us-east-1-941656036254/tensorboard/pytorch-tb-profiling-2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-tb-profiling-2-2022-05-28-16-09-48-370\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-941656036254/pytorch-tb-profiling-2-2022-05-28-16-09-48-370/source/sourcedir.tar.gz\",\"module_name\":\"train_resnet_tb\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_resnet_tb.py\"}\n",
      "SM_USER_ARGS=[\"--batch-size\",\"16\",\"--feature-extract\",\"False\",\"--input-size\",\"224\",\"--num-epochs\",\"5\",\"--tb-s3-url\",\"s3://sagemaker-us-east-1-941656036254/tensorboard/pytorch-tb-profiling-2\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_CHANNEL_VAL=/opt/ml/input/data/val\n",
      "SM_HP_BATCH-SIZE=16\n",
      "SM_HP_FEATURE-EXTRACT=false\n",
      "SM_HP_INPUT-SIZE=224\n",
      "SM_HP_NUM-EPOCHS=5\n",
      "SM_HP_TB-S3-URL=s3://sagemaker-us-east-1-941656036254/tensorboard/pytorch-tb-profiling-2\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220524-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.8 train_resnet_tb.py --batch-size 16 --feature-extract False --input-size 224 --num-epochs 5 --tb-s3-url s3://sagemaker-us-east-1-941656036254/tensorboard/pytorch-tb-profiling-2\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "INFO:__main__:Collected hyperparameters: Namespace(batch_size=16, feature_extract=True, input_size=224, model_name='squeezenet', num_epochs=5, tb_s3_url='s3://sagemaker-us-east-1-941656036254/tensorboard/pytorch-tb-profiling-2').Following args are not parsed correctly and won't be used: [].\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "0%|          | 0.00/44.7M [00:00<?, ?B/s]\n",
      "33%|███▎      | 14.7M/44.7M [00:00<00:00, 154MB/s]\n",
      "69%|██████▉   | 30.7M/44.7M [00:00<00:00, 162MB/s]\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 163MB/s]\n",
      "INFO:__main__:Params to learn:conv1.weight, bn1.weight, bn1.bias, layer1.0.conv1.weight, layer1.0.bn1.weight, layer1.0.bn1.bias, layer1.0.conv2.weight, layer1.0.bn2.weight, layer1.0.bn2.bias, layer1.1.conv1.weight, layer1.1.bn1.weight, layer1.1.bn1.bias, layer1.1.conv2.weight, layer1.1.bn2.weight, layer1.1.bn2.bias, layer2.0.conv1.weight, layer2.0.bn1.weight, layer2.0.bn1.bias, layer2.0.conv2.weight, layer2.0.bn2.weight, layer2.0.bn2.bias, layer2.0.downsample.0.weight, layer2.0.downsample.1.weight, layer2.0.downsample.1.bias, layer2.1.conv1.weight, layer2.1.bn1.weight, layer2.1.bn1.bias, layer2.1.conv2.weight, layer2.1.bn2.weight, layer2.1.bn2.bias, layer3.0.conv1.weight, layer3.0.bn1.weight, layer3.0.bn1.bias, layer3.0.conv2.weight, layer3.0.bn2.weight, layer3.0.bn2.bias, layer3.0.downsample.0.weight, layer3.0.downsample.1.weight, layer3.0.downsample.1.bias, layer3.1.conv1.weight, layer3.1.bn1.weight, layer3.1.bn1.bias, layer3.1.conv2.weight, layer3.1.bn2.weight, layer3.1.bn2.bias, layer4.0.conv1.weight, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.conv2.weight, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.downsample.0.weight, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.1.conv1.weight, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.conv2.weight, layer4.1.bn2.weight, layer4.1.bn2.bias, fc.weight, fc.bias,\n",
      "Initializing Datasets and Dataloaders...\n",
      "[W CPUAllocator.cpp:305] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "Epoch 1: train loss 2.16080584016939, accuracy 0.49583333333333335,  in 59.31428837776184 sec. Total number of steps: 15\n",
      "Epoch 1: val loss 2.606760590983969, accuracy 0.5138888888888888,  in 11.083675861358643 sec. Total number of steps: 9\n",
      "Epoch 2: train loss 4.486370591322581, accuracy 0.06666666666666667,  in 52.67807197570801 sec. Total number of steps: 15\n",
      "Epoch 2: val loss 0.9211303566892942, accuracy 0.5138888888888888,  in 10.971695184707642 sec. Total number of steps: 9\n",
      "Epoch 3: train loss 2.678312364220619, accuracy 0.18333333333333332,  in 52.873849868774414 sec. Total number of steps: 15\n",
      "Epoch 3: val loss 1.7081236332241032, accuracy 0.5138888888888888,  in 10.551691770553589 sec. Total number of steps: 9\n",
      "Epoch 4: train loss 3.3992934981981913, accuracy 0.11666666666666667,  in 53.34251523017883 sec. Total number of steps: 15\n",
      "Epoch 4: val loss 1.1757081196539931, accuracy 0.5138888888888888,  in 10.909832239151001 sec. Total number of steps: 9\n",
      "Epoch 5: train loss 2.801674481232961, accuracy 0.15,  in 51.91814112663269 sec. Total number of steps: 15\n",
      "Epoch 5: val loss 1.3110921523637242, accuracy 0.5138888888888888,  in 10.637210607528687 sec. Total number of steps: 9\n",
      "2022-05-28 16:23:42,084 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2022-05-28 16:23:54 Uploading - Uploading generated training model\n",
      "2022-05-28 16:23:54 Completed - Training job completed\n",
      "Training seconds: 735\n",
      "Billable seconds: 735\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs={\"train\":f\"{data_url}/train\", \"val\":f\"{data_url}/val\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02fb69b38420c3d4e00e3a2af627e83f052bc85ba6fe46654fe57240b48dcaee"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sagemaker2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
