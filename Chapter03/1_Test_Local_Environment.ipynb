{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e59c410",
   "metadata": {},
   "source": [
    "## Setting up local environment for SageMaker \n",
    "\n",
    "There are a number of benefits of doing your initial development locally (on your laptop or desktop machine), specifically: \n",
    "- You don’t incur any running costs for doing your development locally.\n",
    "- You can choose preferred IDE which result in more efficient development cycles. \n",
    "\n",
    "However, local development runtime also has certain limitations. For instance, you cannot test and profile your code on different hardware devices. Getting the latest GPU devices designed for DL workloads can be impractical and not cost efficient. That’s why, in many cases, you will do initial development and testing of your DL code using a CPU device to troubleshoot initial issues and then do the final code profiling and tweaking on cloud instances with access to target GPU devices. \n",
    "\n",
    "SageMaker provides a number of SDKs to allow integration between local environment and AWS cloud. Let’s do a practical example of how to configure your local environment to work with remote SageMaker resources.\n",
    "\n",
    "### Configuring Python Environment \n",
    "\n",
    "We start our configuration by setting up and configuring Python environment with AWS integration. It’s recommended to use Conda environment management software to isolate your SageMaker local environment. You can start by installing Conda on your local machine using appropriate installation method (depends on your local OS). Once Conda is installed, you can create a new Python environment by running the following command in your terminal window: \n",
    "\n",
    "```bash\n",
    "conda create -n sagemaker python=3.9\n",
    "```\n",
    "\n",
    "Note that we are explicitly specifying which version of Python interpreter to use in this environment.  Next, we switch to create environment and install AWS and SageMaker SDKs: \n",
    "\n",
    "```bash\n",
    "conda activate sagemaker \n",
    "pip install boto3 awscli sagemaker \n",
    "```\n",
    "\n",
    "Let’s review SDKs we just installed: \n",
    "- `awscli` is an AWS CLI toolkit which allows you to programmatically work with any AWS service. It also provides mechanism to store and use AWS credentials locally. \n",
    "- `boto3` is a Python SDK to manage your AWS resources. It uses credentials established by AWS CLI toolkit to cryptographically sign any management requests and, thus, authenticate in AWS.  \n",
    "- `sagemaker` Python SDK should be already familiar for you at this point of book as we used it in previous chapters to interact with SageMaker resources such as training jobs or inference endpoints. Unlike `boto3`, SageMaker SDK abstracts many aspects of the management of underlying resources and is generally recommended whenever you need to programmatically manage your SageMaker workloads. \n",
    "\n",
    "Before we proceed, we first need to configure AWS credentials. To do so, you will need to run the following command in your terminal and provide your AWS Access and Secret keys: \n",
    "\n",
    "```bash\n",
    "aws configure \n",
    "```\n",
    "\n",
    "You can read the details of how to setup AWS credentials here: https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html \n",
    "\n",
    "### Configuring Jupyter environment  \n",
    "\n",
    "Once we have basic Python environments configured and have your AWS credentials established, we are ready to start Jupyter server. In this example, we will use JupyterLab environment. However, you are free to configure your own IDE for this purpose as many IDEs, such as PyCharm and Visual Studio Code, support Jupyter Notebooks via plugins or natively. The additional benefit of such approach is that you can easily switch between your notebooks and training and inference scripts within the same IDE. \n",
    "\n",
    "To install JupyterLab and create a kernel, run the following commands in your terminal: \n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge jupyterlab \n",
    "python -m ipykernel install --user --name sagemaker \n",
    "```\n",
    "\n",
    "Next, we start the JupyterLab server on your machine: \n",
    "\n",
    "```bash\n",
    "jupyter lab \n",
    "```\n",
    "\n",
    "Your JupyterLab server should be now available on http://localhost:8888 \n",
    "\n",
    "## Testing Local Environment \n",
    "\n",
    "Once we installed Conda environment and JupyterLab, we can test that we can programmatically interact with SageMaker from local notebook. Please make sure to select to select appropriate `sagemaker` kernel before running cells below.\n",
    "\n",
    "Let's start by establishing SageMaker session and specifying SageMaker execution role ARN. Please note, that you will need to manually define your execution role. For this, you can navigate to AWS IAM service and look for SageMaker execution role on \"Roles\" tab (see screenshot below). \n",
    "\n",
    "![title](static/iam_sagemaker_exec_role.png)\n",
    "\n",
    "\n",
    "For SageMaker managed environments such as SageMaker Studio or SageMaker Notebooks you get use method `get_execution_role()` to retrieve execution role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8440272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session()\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "role = f\"arn:aws:iam::{account}:role/service-role/AmazonSageMaker-ExecutionRole-<YOUR_ROLE_ID>\" \n",
    "# role = get_execution_role() # this method allows to automatically get attached role from SageMaker managed runtimes. Will not work on local environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bacb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "import os\n",
    "\n",
    "pytorch_estimator = PyTorch(\n",
    "                        session=session,\n",
    "                        entry_point=f'{os.getcwd()}/sources/cifar10.py',\n",
    "                        role=role,\n",
    "                        instance_type=\"ml.m4.xlarge\",\n",
    "                        instance_count=1,\n",
    "                        job_name=\"test\",\n",
    "                        framework_version=\"1.9.0\",\n",
    "                        py_version=\"py38\",\n",
    "                        hyperparameters={\n",
    "                            \"epochs\": 1,\n",
    "                            \"batch-size\": 16\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "pytorch_estimator.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf399607",
   "metadata": {},
   "source": [
    "Once training job is done, you can explore locally training results and where output artifacts have been stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded8dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_estimator.latest_training_job.describe()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cae6ef5e525c6d5a8daa33565a4e32326fcdb22bb4405c41032726ef6ebbb77e"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
