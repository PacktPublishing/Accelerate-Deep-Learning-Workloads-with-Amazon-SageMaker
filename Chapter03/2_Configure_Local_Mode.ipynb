{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a6507d",
   "metadata": {},
   "source": [
    "## Configuring SageMaker Local Mode\n",
    "\n",
    "Let’s train simple model in local mode and then deploy inference endpoint locally.\n",
    "\n",
    "We start by installing all required dependencies for local mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7fa453",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install 'sagemaker[local]' –upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be70db2f",
   "metadata": {},
   "source": [
    "We then configure SageMaker local runtime. Note, that we are using LocalSession class to let SageMaker SDK know that we want to provision resources locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ebd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.local import LocalSession\n",
    "\n",
    "sagemaker_local_session = LocalSession()\n",
    "sagemaker_local_session.config = {'local': {'local_code': True}}\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "role = f\"arn:aws:iam::{account}:role/service-role/AmazonSageMaker-ExecutionRole-<YOUR_ROLE_ID>\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb46cb",
   "metadata": {},
   "source": [
    "In this notebook we intend to use public PyTorch image from SageMaker ECR repository. Please note, that you need to specify your target AWS Region in the command below (e.g. \"us-east-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a275ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loging to Sagemaker ECR with Deep Learning Containers, so SageMaker can pull images in local mode\n",
    "!aws ecr get-login-password --region <YOUR_AWS_REGION> | docker login --username AWS --password-stdin 763104351884.dkr.ecr.<YOUR_AWS_REGION>.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a147a77",
   "metadata": {},
   "source": [
    "Now, we need to decide whether we will use GPU (if available) or CPU device (default choice). The following code snippet determines whether CUDA compatible device is available (“local_gpu” value), and if not, defaults to CPU device ( “local” value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c2eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "instance_type = \"local\"\n",
    "\n",
    "try:\n",
    "    if subprocess.call(\"nvidia-smi\") == 0:\n",
    "        ## Set type to GPU if one is present\n",
    "        instance_type = \"local_gpu\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981de94f",
   "metadata": {},
   "source": [
    "Once we define which local device, we configure and run SageMaker training job. SageMaker Python SDK performs following operations automatically:\n",
    "- pull appropriate PyTorch image from public ECR repository.\n",
    "- generate docker-compose YML file with appropriate volume mount points to access code and training data.\n",
    "- starts docker container with train command.\n",
    "\n",
    "SageMaker will output the output of docker compose command and the STDOUT/STDERR of training container to Jupyter cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1728ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "import os\n",
    "\n",
    "# Configure an MXNet Estimator (no training happens yet)\n",
    "pytorch_estimator = PyTorch(\n",
    "                        session=sagemaker_local_session,\n",
    "                        entry_point=f'{os.getcwd()}/sources/cifar10.py',\n",
    "                        role=role,\n",
    "                        instance_type=instance_type,\n",
    "                        instance_count=1,\n",
    "                        job_name=\"test\",\n",
    "                        framework_version=\"1.9.0\",\n",
    "                        py_version=\"py38\",\n",
    "                        hyperparameters={\n",
    "                            \"epochs\": 1,\n",
    "                            \"batch-size\": 16\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "pytorch_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c5ab7",
   "metadata": {},
   "source": [
    "After training job finished let’s see how we can deploy trained model to local real-time endpoint. Note, by default we are training only for single epoch, so don’t expect great results!\n",
    "You can deploy inference container locally just by running `deploy()` method on your estimator:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08407de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_estimator.deploy(initial_instance_count=1, instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e360d82",
   "metadata": {},
   "source": [
    "Once endpoint is deployed, SageMaker SDK will start sending output of model server to Jupyter cell. You can. Also observe container logs in Docker client UI or via terminal command `docker logs CONTAINER_ID`. We can send now test image and observe how our inference scripts handles inference request in docker logs.\n",
    "\n",
    "For this we first download locally CIFAR10 dataset and then pick one of test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7bf723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move this down on inference test\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f151cf03",
   "metadata": {},
   "source": [
    "We can send now test image and observe how our inference scripts handles inference request in docker logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json \n",
    "\n",
    "\n",
    "payload = testset[0][0].numpy().tobytes()\n",
    "url = 'http://127.0.0.1:8080/invocations'\n",
    "content_type = 'application/x-npy'\n",
    "accept_type = \"application/json\"\n",
    "headers = {'content-type': content_type, 'accept': accept_type}\n",
    "\n",
    "response = requests.post(url, data=payload, headers=headers)\n",
    "print(f\"Model response: {json.loads(response.content)[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cae6ef5e525c6d5a8daa33565a4e32326fcdb22bb4405c41032726ef6ebbb77e"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
