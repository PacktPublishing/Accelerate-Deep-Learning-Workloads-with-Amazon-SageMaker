{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb6e548",
   "metadata": {},
   "source": [
    "# Extending SageMaker Training Container\n",
    "\n",
    "## Overview\n",
    "In this notebook we will learn how to extend SageMaker container as a base image for your custom container image. Modifying pre-build containers can be beneficial in following scenarios:\n",
    "- you need to add additional dependencies (for instance, ones which needs to be compiled from sources) or significantly re-configure runtime environment.\n",
    "- you want to minimize development and testing efforts of your container and rely for most part on tested by AWS functionality of base container.\n",
    "\n",
    "## Problem Statement\n",
    "We will re-use code assets from the our previous notebook in this chapter, where we trained and deploy NLP model to classify articles based on their content. However, unlike previous container we will modify our runtime environment and *install latest stable HuggingFace Transformer from Github master branch*. This modification will be implemented in our custom container image.\n",
    "\n",
    "## Developing Training Container\n",
    "\n",
    "First of, we need to identify which base image we will use. AWS published all available Deep Learning containers here: https://github.com/aws/deep-learning-containers/blob/master/available_images.md\n",
    "\n",
    "Since we plan to use re-install from scratch HugggingFace Transformer library anyway, we may choose PyTorch base image. As of time of writing, the latest PyTorch SageMaker container was `763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.9.0-gpu-py38-cu111-ubuntu20.04`.\n",
    "\n",
    "*Note, this container URI is for AWS East-1 region and will be different for other AWS regions. Please consult with refenced above AWS article on correct URI for your region.*\n",
    "\n",
    "To build a new containers we will need to:\n",
    "- create Dockerfile with runtime instructions.\n",
    "- build container image locally.\n",
    "- push new container image to `container registry`. As a container registry in this example we will use Elastic Container Registry - a managed service from AWS well integrated with SageMaker ecosystem.\n",
    "\n",
    "\n",
    "### Reviewing Dockerfile\n",
    "Let's take a look on key components of our Dockerfile (please execute cell below to render Dockerfile content):\n",
    "- we choose to use SageMaker PyTorch image as a base.\n",
    "- install latest PyTorch and HuggingFace Transformers.\n",
    "- copy our training script for previous lab into container.\n",
    "- define `SAGEMAKER_SUBMIT_DIRECTORY` and `SAGEMAKER_PROGRAM` environmental variables, so SageMaker knows which training script to execute at container start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f60eeee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33m763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.9.0-gpu-py38-cu111-ubuntu20.04\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mRUN\u001b[39;49;00m pip3 install git+https://github.com/huggingface/transformers\n",
      "\n",
      "\u001b[34mENV\u001b[39;49;00m SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      "\u001b[34mENV\u001b[39;49;00m SAGEMAKER_PROGRAM train.py\n",
      "\n",
      "\u001b[34mCOPY\u001b[39;49;00m 1_sources/train.py  \u001b[31m$SAGEMAKER_SUBMIT_DIRECTORY\u001b[39;49;00m/\u001b[31m$SAGEMAKER_PROGRAM\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize -l docker 2_sources/Dockerfile.training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac21af",
   "metadata": {},
   "source": [
    "### Building and Pushing Container Image\n",
    "\n",
    "Once we have our Dockerfile ready, we need to build and push container image to registry. We start by authentificating with ECR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89fa8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loging to Sagemaker ECR with Deep Learning Containers\n",
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com\n",
    "# loging to your private ECR\n",
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin {account}.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92685b8b",
   "metadata": {},
   "source": [
    "Now, we are ready to build and push container to ECR. For this, we provide as part of this repo a utility script `build_and_push.sh` to automate this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3cd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = \"extended-pytorch-training\"\n",
    "tag = \"latest\"\n",
    "\n",
    "!./build_and_push.sh {image_name} {tag} 2_sources/Dockerfile.training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42f7c71",
   "metadata": {},
   "source": [
    "### Scheduling Training Job\n",
    "\n",
    "We have our extended PyTorch container in ECR, and we are ready to execute SageMaker training job. Training job configuration will be similar to Script Mode example with one noteable different: instead of `HuggingFaceEstimator` object we will use a generic `Sagemaker Estimator` which allows to work with custom images. Note, that you need to update parameter `iamge_uri` with reference to image URI in your ECR. You can find it by navigating to \"ECR\" service in your AWS Console and finding extended container there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "825b156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"epochs\":1,\n",
    "    # 2 params below may need to updated if non-GPU instances is used for training\n",
    "    \"per-device-train-batch-size\":16, \n",
    "    \"per-device-eval-batch-size\":64,\n",
    "    \"warmup-steps\":100,\n",
    "    \"logging-steps\":100,\n",
    "    \"weight-decay\":0.01    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e45b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please provide S3 URIs of test dataset from \"Script Mode\" example\n",
    "train_dataset_uri=\"s3://<YOUR S3 BUCKET>/newsgroups/train_dataset.csv\"\n",
    "test_dataset_uri=\"s3://<YOUR S3 BUCKET>/newsgroups/test_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2cd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "estimator = Estimator(\n",
    "    image_uri=\"<UPDATE WITH YOUR IMAGE URI FROM ECR>\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_type=\"ml.p2.xlarge\",\n",
    "    instance_count=1,\n",
    "    role=role\n",
    ")\n",
    "\n",
    "estimator.fit({\n",
    "    \"train\":train_dataset_uri,\n",
    "    \"test\":test_dataset_uri\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd99df",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, you learned how to extend SageMaker PyTorch training container to address some specific runtime requirements with now code changes in training scripts and minimal development efforts.\n",
    "\n",
    "In next example we will learn how to build SageMaker-compatible container using official TensorFlow image. This approach allows for maximum flexibility while requires more development efforts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
