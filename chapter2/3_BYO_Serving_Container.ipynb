{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f29a56f",
   "metadata": {},
   "source": [
    "## BYO Serving Container on SageMaker\n",
    "\n",
    "In this notebook, we will develop SageMaker-compatible container for inference. We will use latest TensorFlow container as a base image and use AWS Multi-Model Server (\"MMS\") as a model server. Please note that MMS is one of several ML model serving options.\n",
    "\n",
    "### Problem Overview\n",
    "We will use pre-trained [VGG16 model](https://arxiv.org/pdf/1409.1556.pdf) to classify content of the images into 1000 categories. The model is trained on ImageNet dataset.\n",
    "\n",
    "We will use Keras Deep Learning library which is now a part of TensorFlow code base. Hence, we choose choose latest TensorFlow container as a base. \n",
    "\n",
    "### Developing Serving Container\n",
    "When deploying serving container to endpoint SageMaker runs `docker run <YOUR BYO IMAGE> serve` command. To comply with this requirement it's reccommended to use exec format of ENTRYPOINT instruction in your Dockerfile.\n",
    "\n",
    "Let's review our BYO Dockerfile:\n",
    "- we use latest tensorflow-devel container as base.\n",
    "- we install general and SageMaker specific dependencies.\n",
    "- we copy our model serving scripts to container.\n",
    "- we specify ENTRYPOINT and CMD instructions to comply with SageMaker requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b527889",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize -O linenos=1 -l docker 3_sources/Dockerfile.inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368598fd",
   "metadata": {},
   "source": [
    "### Developing Model Serving Scripts\n",
    "\n",
    "Inference scripts in case of BYO container are specific to chosen model server. In our case we are using AWS MMS server and developed scripts according to it's requirements. You find more details here: https://github.com/awslabs/multi-model-server/blob/master/docs/custom_service.md\n",
    "\n",
    "In this example we don't intend to cover MMS and development of inference scripts in details. However, it's worth highlighting some key script aspects:\n",
    "- `dockerd_entrypoint.py` is an excuitable which starts MMS server when `serve` argument is passed to it.\n",
    "- `model_handler.py` implements model loading and model serving logics. Note, that method `handle()` checks if model is already loaded into memory. If it's not, it will load model into memory once and then proceed to handling serving request which includes:\n",
    "    - deserializing request payload.\n",
    "    - running predictions.\n",
    "    - serializing predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize 3_sources/src/dockerd_entrypoint.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbdf9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize 3_sources/src/model_handler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381b200",
   "metadata": {},
   "source": [
    "### Building BYO Container\n",
    "\n",
    "Once we have Dockerfile and inference scripts are ready, we can proceed and build container. We start by importing SageMaker utilities and providing configuration settings for our container and SageMaker model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad97e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = session.boto_region_name\n",
    "\n",
    "# Configuration settings\n",
    "model_name=\"vgg16-model\"\n",
    "endpoint_name= model_name+\"-mms-endpoint\"\n",
    "tag = \"v1\"\n",
    "image_uri = f\"{account}.dkr.ecr.{region}.amazonaws.com/{model_name}:{tag}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbbb860",
   "metadata": {},
   "source": [
    "Now, we need to authenticate in our private ECR before we can push there BYO container image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a4b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loging to your private ECR\n",
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin {account}.dkr.ecr.{region}.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fe0e17",
   "metadata": {},
   "source": [
    "After that we are ready to build BYO container and push it to ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b74c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./build_and_push.sh {model_name} {tag} 3_sources/Dockerfile.inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa208a",
   "metadata": {},
   "source": [
    "## Deploying SageMaker Endpoint\n",
    "\n",
    "We use generic `Model` object to configure SageMaker model and endpoint which allows us to use BYO container image. Note, that since we download model from public model zoo, we don't need to provide `model_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a53be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import Model\n",
    "\n",
    "mms_model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=None,\n",
    "    role=role,\n",
    "    name=model_name,\n",
    "    sagemaker_session=session\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3574e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\", \n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3097d8c9",
   "metadata": {},
   "source": [
    "## Test SageMaker Endpoint\n",
    "\n",
    "To test the endpoint we will use a sample image. Feel free to pick several other images of your choice (make sure they have object belonging to one of 1000 categories from ImageNet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28cc0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE = \"sample_image.jpg\"\n",
    "! wget -O {TEST_IMAGE} https://farm1.static.flickr.com/56/152004091_5bfbc69bb3.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d516ed",
   "metadata": {},
   "source": [
    "VGG16 model expects an image of size 224x224 pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def resize_image(filename):\n",
    "    img = cv2.imread('152004091_5bfbc69bb3.jpg')\n",
    "    resized_img = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    resized_filename = \"resized_\"+TEST_IMAGE\n",
    "\n",
    "    cv2.imwrite(resized_filename, resized_img)\n",
    "\n",
    "    plt.imshow(cv2.imread(resized_filename))\n",
    "    plt.show()\n",
    "    \n",
    "    return resized_filename\n",
    "\n",
    "resized_test_image = resize_image(TEST_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505b07e2",
   "metadata": {},
   "source": [
    "To test the endpoint, we will use `boto3.sagemaker-runtime` client which allows to construct HTTP request and send it to defined SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79450fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "accept_type = \"application/json\"\n",
    "content_type = 'image/jpeg'\n",
    "headers = {'content-type': content_type}\n",
    "payload = open(resized_test_image, 'rb')\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=payload,\n",
    "    ContentType=content_type,\n",
    "    Accept = accept_type\n",
    ")\n",
    "\n",
    "\n",
    "most_likely_label = response['Body'].read()\n",
    "\n",
    "print(most_likely_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7310518",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, we developed a custom BYO serving container. As you may observe, developing BYO container is most flexible approach to configure runtime. However, it requires more development efforts and expertise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
