{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Container endpoints\n",
    "\n",
    "In this example we will deploy two different models for summarization and Q&A tasks.\n",
    "Please note that loading and packaging models may take several minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload model data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import os\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role() \n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'multi-model'\n",
    "s3_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "region = sagemaker_session.boto_region_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Multi Model Endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_MODEL = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "GER_MODEL = \"oliverguhr/german-sentiment-bert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('models/english_sentiment/tokenizer_config.json',\n",
       " 'models/english_sentiment/special_tokens_map.json',\n",
       " 'models/english_sentiment/vocab.txt',\n",
       " 'models/english_sentiment/added_tokens.json')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve english model\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "en_tokenizer = DistilBertTokenizer.from_pretrained(EN_MODEL)\n",
    "en_model = DistilBertForSequenceClassification.from_pretrained(EN_MODEL)\n",
    "\n",
    "inputs = en_tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = en_model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "predictions = en_model.config.id2label[predicted_class_id]\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "en_model_path = \"models/english_sentiment\"\n",
    "os.makedirs(en_model_path, exist_ok=True)\n",
    "\n",
    "en_model.save_pretrained(save_directory=en_model_path)\n",
    "en_tokenizer.save_pretrained(save_directory=en_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('models/german_sentiment/tokenizer_config.json',\n",
       " 'models/german_sentiment/special_tokens_map.json',\n",
       " 'models/german_sentiment/vocab.txt',\n",
       " 'models/german_sentiment/added_tokens.json')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve German model\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "ger_tokenizer = BertTokenizer.from_pretrained(GER_MODEL)\n",
    "ger_model = BertForSequenceClassification.from_pretrained(GER_MODEL)\n",
    "\n",
    "inputs = ger_tokenizer(\"Das ist gar nicht mal so gut\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = ger_model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "predictions = ger_model.config.id2label[predicted_class_id]\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "ger_model_path = \"models/german_sentiment\"\n",
    "os.makedirs(ger_model_path, exist_ok=True)\n",
    "\n",
    "en_model.save_pretrained(save_directory=ger_model_path)\n",
    "en_tokenizer.save_pretrained(save_directory=ger_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Inference Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize 1_src/en_inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize 2_src/get_inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir models/english_sentiment/code\n",
    "! cp 1_src/en_inference.py models/english_sentiment/code/inference.py\n",
    "! tar -czvf models/english_sentiment.tar.gz -C models/english_sentiment/ .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir models/german_sentiment/code\n",
    "! cp 1_src/ger_inference.py models/german_sentiment/code/inference.py\n",
    "! tar -czvf models/german_sentiment.tar.gz -C models/german_sentiment/ .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model_data = sagemaker_session.upload_data('models/english_sentiment.tar.gz', bucket=bucket,key_prefix=prefix)\n",
    "ger_model_data = sagemaker_session.upload_data('models/german_sentiment.tar.gz', bucket=bucket,key_prefix=prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.10.2-transformers4.17.0-cpu-py38-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "HF_VERSION = '4.17.0'\n",
    "PT_VERSION = 'pytorch1.10.2'\n",
    "TF_VERSION = \"tensorflow2.6.3\"\n",
    "\n",
    "pt_container_uri = image_uris.retrieve(framework='huggingface',\n",
    "                                region=region,\n",
    "                                version=HF_VERSION,\n",
    "                                image_scope='inference',\n",
    "                                base_framework_version=PT_VERSION,\n",
    "                                #py_version='py38',\n",
    "                                #container_version='ubuntu20.04',\n",
    "                                instance_type='ml.c5.xlarge')\n",
    "\n",
    "print(pt_container_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_data_path = f\"s3://{bucket}/{prefix}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "container  = {\n",
    "    'Image': pt_container_uri,\n",
    "    'ContainerHostname': 'MultiModel',\n",
    "    'Mode': 'MultiModel',\n",
    "    'ModelDataUrl': mm_data_path,\n",
    "    'Environment': {\n",
    "\t    'SAGEMAKER_PROGRAM':'inference.py',\n",
    "\t    'SAGEMAKER_SUBMIT_DIRECTORY':mm_data_path\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Multi Container Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = sagemaker_session.sagemaker_client\n",
    "runtime_sm_client = sagemaker_session.sagemaker_runtime_client\n",
    "\n",
    "instance_type = \"ml.m5.4xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "unique_id = datetime.datetime.now().strftime(\"%Y-%m-%d%H-%M-%S\")\n",
    "\n",
    "model_name = f\"mme-sentiment-model-{unique_id}\"\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer=container,\n",
    "    ExecutionRoleArn=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = f\"{model_name}-ep-config\"\n",
    "\n",
    "endpoint_config = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"prod\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InstanceType\": instance_type,\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"{model_name}-ep\"\n",
    "\n",
    "endpoint = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mce-nlp-model-2022-08-2511-01-19-ep\n",
      "mce-nlp-model-2022-08-2511-01-19\n"
     ]
    }
   ],
   "source": [
    "print(endpoint_name)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Multi Model Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "ger_input = \"Der Test verlief positiv.\"\n",
    "en_input = \"Test results are positive.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=\"application/json\",\n",
    "    TargetModel=\"english_sentiment.tar.gz\",\n",
    "    Body=json.dumps(en_input),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = json.loads(en_response[\"Body\"].read().decode())\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.7555540800094604, 'start': 77, 'end': 92, 'answer': 'Selva Amazónica'}\n"
     ]
    }
   ],
   "source": [
    "ger_response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=\"application/json\",\n",
    "    TargetModel=\"german_sentiment.tar.gz\",\n",
    "    Body=json.dumps(ger_input),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = json.loads(ger_response[\"Body\"].read().decode())\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'a4628488-6003-4618-8569-e9c6541d79c2',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a4628488-6003-4618-8569-e9c6541d79c2',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 25 Aug 2022 17:34:35 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_model(ModelName = model_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02fb69b38420c3d4e00e3a2af627e83f052bc85ba6fe46654fe57240b48dcaee"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sagemaker2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
